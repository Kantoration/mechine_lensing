first report:
Here’s a concise, implementation-ready plan plus proposed code to add a LensGNN module that reconstructs κ(x,y), α(x,y), and supports physics losses, uncertainty, and domain adaptation. It’s composable with existing CNN/ViT backbones and LensPINN, and keeps dependencies minimal (pure PyTorch).

### Plan (what we’ll add and how it wires in)
- Models
  - Add `LensGNN` under `src/models/gnn/lens_gnn.py`: image → node graph → message passing → dense maps ψ, κ, α. Supports MC-dropout and optional variational outputs for per-pixel uncertainty.
  - Add `LensGNNSystem` (Lightning) that:
    - Computes supervised losses for κ/α (when labels available).
    - Enforces physics: Poisson (∇²ψ ≈ 2κ) and α = ∇ψ.
    - Adds domain adaptation: consistency loss on unlabeled real images (weak vs strong aug), plus optional pseudo-labeling with confidence threshold.
  - Add a small “latent verification head” to feed κ, α, uncertainties into your existing detection/verification head (binary classifier), keeping it modular.
- Physics utilities
  - Add `src/physics/lens_physics.py`: finite-difference gradient, Laplacian, physics consistency losses.
- Integration
  - Register `lens_gnn` in `src/models/ensemble/registry.py`.
  - Support in `src/models/unified_factory.py` so it can be instantiated like other backbones and composed into ensembles or physics-informed wrappers.
  - Optionally expose as a member in calibrated ensembles; temperature scaling remains at evaluator/ensemble level (already supported).
- Domain adaptation
  - In `LensGNNSystem`, add consistency loss for unlabeled batches (toggle via config), pseudo-labeling with temperature/thresholding.
- Tests
  - `tests/test_lens_gnn.py`: shapes, physics constraint reductions, MC-dropout variance check, domain adaptation loss well-defined.
- Configs
  - `configs/lens_gnn.yaml` to drive training, losses, uncertainty, and DA toggles.

Below are proposed new files/edits you can copy in. They use standard PyTorch and Lightning only.

New file: src/physics/lens_physics.py
```python
from __future__ import annotations
from typing import Dict, Tuple, Optional
import torch
import torch.nn as nn
import torch.nn.functional as F

Tensor = torch.Tensor

def sobel_kernels(device: torch.device, dtype: torch.dtype) -> Tuple[Tensor, Tensor]:
    kx = torch.tensor([[1, 0, -1],
                       [2, 0, -2],
                       [1, 0, -1]], dtype=dtype, device=device) / 8.0
    ky = torch.tensor([[1, 2, 1],
                       [0, 0, 0],
                       [-1, -2, -1]], dtype=dtype, device=device) / 8.0
    return kx.view(1, 1, 3, 3), ky.view(1, 1, 3, 3)

def laplacian_kernel(device: torch.device, dtype: torch.dtype) -> Tensor:
    k = torch.tensor([[0, 1, 0],
                      [1, -4, 1],
                      [0, 1, 0]], dtype=dtype, device=device)
    return k.view(1, 1, 3, 3)

def grad2d(field: Tensor) -> Tuple[Tensor, Tensor]:
    """
    Compute gradient of scalar field with Sobel filters.
    Args:
        field: [B, 1, H, W]
    Returns:
        (gx, gy) each [B, 1, H, W]
    """
    assert field.dim() == 4 and field.size(1) == 1
    kx, ky = sobel_kernels(field.device, field.dtype)
    gx = F.conv2d(field, kx, padding=1)
    gy = F.conv2d(field, ky, padding=1)
    return gx, gy

def laplacian2d(field: Tensor) -> Tensor:
    """
    Discrete Laplacian.
    Args:
        field: [B, 1, H, W]
    Returns:
        lap: [B, 1, H, W]
    """
    k = laplacian_kernel(field.device, field.dtype)
    return F.conv2d(field, k, padding=1)

class LensPhysicsLoss(nn.Module):
    """
    Physics consistency for gravitational lensing:
      - Poisson: ∇²ψ ≈ 2 κ (under standard lensing units)
      - Deflection: α = ∇ψ (α_x, α_y)
    """
    def __init__(self, w_poisson: float = 1.0, w_deflection: float = 1.0, robust_delta: float = 0.0):
        super().__init__()
        self.w_poisson = float(w_poisson)
        self.w_deflection = float(w_deflection)
        self.robust_delta = float(robust_delta)

    def huber(self, diff: Tensor) -> Tensor:
        if self.robust_delta <= 0:
            return diff.pow(2)
        return F.huber_loss(diff, torch.zeros_like(diff), delta=self.robust_delta, reduction="none")

    def forward(
        self,
        psi: Tensor,            # [B, 1, H, W]
        kappa: Tensor,          # [B, 1, H, W]
        alpha: Tensor           # [B, 2, H, W] (alpha_x, alpha_y)
    ) -> Dict[str, Tensor]:
        lap = laplacian2d(psi)  # [B, 1, H, W]
        gx, gy = grad2d(psi)    # [B, 1, H, W]

        poisson_err = lap - 2.0 * kappa
        deflect_err_x = gx - alpha[:, 0:1, ...]
        deflect_err_y = gy - alpha[:, 1:2, ...]
        deflect_err = torch.cat([deflect_err_x, deflect_err_y], dim=1)

        l_poisson = self.huber(poisson_err).mean()
        l_deflect = self.huber(deflect_err).mean()

        total = self.w_poisson * l_poisson + self.w_deflection * l_deflect
        return {
            "loss_physics": total,
            "loss_poisson": l_poisson.detach(),
            "loss_deflection": l_deflect.detach(),
        }
```

New file: src/models/gnn/lens_gnn.py
```python
from __future__ import annotations
from typing import Dict, Optional, Tuple
import math
import torch
import torch.nn as nn
import torch.nn.functional as F

Tensor = torch.Tensor

class MLP(nn.Module):
    def __init__(self, in_dim: int, hidden: int, out_dim: int, p_drop: float = 0.1):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hidden),
            nn.ReLU(inplace=True),
            nn.Dropout(p_drop),
            nn.Linear(hidden, hidden),
            nn.ReLU(inplace=True),
            nn.Dropout(p_drop),
            nn.Linear(hidden, out_dim),
        )

    def forward(self, x: Tensor) -> Tensor:
        return self.net(x)

class GraphConv(nn.Module):
    """
    Minimal message passing layer (no external deps).
    kNN graph on grid coordinates; messages via MLP(h_i, h_j, d_ij).
    """
    def __init__(self, node_dim: int, hidden: int, k: int = 8, p_drop: float = 0.1):
        super().__init__()
        self.k = int(k)
        self.msg = MLP(2 * node_dim + 1, hidden, node_dim, p_drop)
        self.norm = nn.LayerNorm(node_dim)

    @staticmethod
    def knn(coords: Tensor, k: int) -> Tensor:
        # coords: [B, N, 2]
        with torch.no_grad():
            dist = torch.cdist(coords, coords)  # [B, N, N]
            idx = dist.topk(k=k + 1, dim=-1, largest=False).indices[..., 1:]  # exclude self
        return idx  # [B, N, k]

    def forward(self, h: Tensor, coords: Tensor) -> Tensor:
        """
        Args:
            h: [B, N, C]
            coords: [B, N, 2] normalized to [-1, 1]
        """
        B, N, C = h.shape
        idx = self.knn(coords, self.k)  # [B, N, k]
        # Gather neighbor features and distances
        nbr = torch.gather(h.unsqueeze(1).expand(B, N, N, C), 2, idx.unsqueeze(-1).expand(B, N, self.k, C))  # [B,N,k,C]
        self_feat = h.unsqueeze(2).expand(B, N, self.k, C)  # [B,N,k,C]
        d = torch.cdist(coords, coords)  # [B,N,N]
        d = torch.gather(d.unsqueeze(1).expand(B, N, N), 2, idx)  # [B,N,k]
        msg_in = torch.cat([self_feat, nbr, d.unsqueeze(-1)], dim=-1)  # [B,N,k,2C+1]
        m = self.msg(msg_in)  # [B,N,k,C]
        m = m.mean(dim=2)     # aggregate neighbors
        out = self.norm(h + m)
        return out

class PatchEncoder(nn.Module):
    """
    Convert image to node features on a coarse grid via strided convs.
    """
    def __init__(self, in_ch: int, feat_dim: int):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(in_ch, 32, 3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, 3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, feat_dim, 3, stride=2, padding=1),
            nn.ReLU(inplace=True),
        )

    def forward(self, x: Tensor) -> Tuple[Tensor, Tuple[int, int]]:
        # x: [B, C, H, W]
        h = self.encoder(x)  # [B, F, H', W']
        B, F, Hp, Wp = h.shape
        nodes = h.flatten(2).transpose(1, 2)  # [B, N, F], N=Hp*Wp
        return nodes, (Hp, Wp)

def make_grid_coords(h: int, w: int, device: torch.device, dtype: torch.dtype) -> Tensor:
    ys = torch.linspace(-1, 1, steps=h, device=device, dtype=dtype)
    xs = torch.linspace(-1, 1, steps=w, device=device, dtype=dtype)
    grid_y, grid_x = torch.meshgrid(ys, xs, indexing="ij")
    coords = torch.stack([grid_x, grid_y], dim=-1).view(-1, 2)  # [N,2]
    return coords

class LensGNN(nn.Module):
    """
    Graph neural network that reconstructs lens potential ψ, surface mass density κ,
    and deflection field α from multi-band images. Enforces physics via losses (external).
    """
    def __init__(
        self,
        in_ch: int = 3,
        node_dim: int = 128,
        n_layers: int = 4,
        k: int = 8,
        p_drop: float = 0.1,
        predict_logvar: bool = True,
    ):
        super().__init__()
        self.encoder = PatchEncoder(in_ch, node_dim)
        self.layers = nn.ModuleList([GraphConv(node_dim, node_dim, k=k, p_drop=p_drop) for _ in range(n_layers)])
        # Heads on node domain
        out_scalar = 2 if predict_logvar else 1
        self.psi_head = nn.Linear(node_dim, out_scalar)   # ψ (and optional logvar)
        self.kappa_head = nn.Linear(node_dim, out_scalar) # κ (and optional logvar)
        # deflection α has 2 channels; if uncertainty, predict per-component
        self.alpha_head = nn.Linear(node_dim, 2 * out_scalar)
        self.predict_logvar = bool(predict_logvar)

    def forward(self, x: Tensor) -> Dict[str, Tensor]:
        """
        Args:
            x: [B, C, H, W] multi-band input (PSF-homogenized if needed)
        Returns:
            dict with dense maps:
              - psi: [B, 1, Hp, Wp]
              - kappa: [B, 1, Hp, Wp]
              - alpha: [B, 2, Hp, Wp]
              - optional logvars: psi_logvar, kappa_logvar, alpha_logvar [B, ...]
        """
        B, C, H, W = x.shape
        nodes, (Hp, Wp) = self.encoder(x)         # [B, N, F]
        N = Hp * Wp
        coords = make_grid_coords(Hp, Wp, x.device, x.dtype).unsqueeze(0).expand(B, N, 2)

        h = nodes
        for layer in self.layers:
            h = layer(h, coords)

        psi_out = self.psi_head(h)               # [B,N,1 or 2]
        kappa_out = self.kappa_head(h)           # [B,N,1 or 2]
        alpha_out = self.alpha_head(h)           # [B,N,2 or 4]

        if self.predict_logvar:
            psi, psi_logvar = psi_out.split([1, 1], dim=-1)
            kappa, kappa_logvar = kappa_out.split([1, 1], dim=-1)
            alpha, alpha_logvar = alpha_out.split([2, 2], dim=-1)
        else:
            psi, kappa = psi_out, kappa_out
            alpha = alpha_out
            psi_logvar = kappa_logvar = alpha_logvar = None

        # reshape back to maps
        def to_map(t: Tensor, ch: int) -> Tensor:
            return t.view(B, Hp, Wp, ch).permute(0, 3, 1, 2).contiguous()

        out = {
            "psi": to_map(psi, 1),
            "kappa": to_map(kappa, 1),
            "alpha": to_map(alpha, 2),
        }
        if self.predict_logvar:
            out["psi_logvar"] = to_map(psi_logvar, 1)
            out["kappa_logvar"] = to_map(kappa_logvar, 1)
            out["alpha_logvar"] = to_map(alpha_logvar, 2)
        return out
```

New file: src/models/heads/latent_verification.py
```python
from __future__ import annotations
from typing import Dict, Optional
import torch
import torch.nn as nn
import torch.nn.functional as F

Tensor = torch.Tensor

class LatentVerificationHead(nn.Module):
    """
    Small head that ingests κ, α (and uncertainties) and outputs a verification logit.
    Can be fused with CNN/ViT global features outside this class if desired.
    """
    def __init__(self, use_uncertainty: bool = True, hidden: int = 128):
        super().__init__()
        in_ch = 1 + 2  # kappa + 2 alpha components
        if use_uncertainty:
            in_ch += 1 + 2  # kappa_logvar + alpha_logvar(2)
        self.reduce = nn.Conv2d(in_ch, 32, kernel_size=3, padding=1)
        self.head = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(32, hidden),
            nn.ReLU(inplace=True),
            nn.Linear(hidden, 1),
        )
        self.use_uncertainty = bool(use_uncertainty)

    def forward(self, latent: Dict[str, Tensor]) -> Tensor:
        xs = [latent["kappa"], latent["alpha"]]
        if self.use_uncertainty and "kappa_logvar" in latent and "alpha_logvar" in latent:
            xs += [latent["kappa_logvar"], latent["alpha_logvar"]]
        x = torch.cat(xs, dim=1)
        x = self.reduce(x)
        logit = self.head(x).squeeze(1)  # [B]
        return logit
```

New file: src/models/gnn/lens_gnn_system.py
```python
from __future__ import annotations
from typing import Dict, Optional
import torch
import torch.nn as nn
import pytorch_lightning as pl

from .lens_gnn import LensGNN
from ..heads.latent_verification import LatentVerificationHead
from ...physics.lens_physics import LensPhysicsLoss

Tensor = torch.Tensor

class LensGNNSystem(pl.LightningModule):
    """
    Lightning wrapper for LensGNN with physics, uncertainty, and domain adaptation.
    Supervised terms are optional; physics + DA can drive learning on unlabeled data.
    """
    def __init__(
        self,
        in_ch: int = 3,
        node_dim: int = 128,
        n_layers: int = 4,
        k: int = 8,
        p_drop: float = 0.1,
        predict_logvar: bool = True,
        # Loss weights
        w_kappa: float = 1.0,
        w_alpha: float = 1.0,
        w_physics: float = 1.0,
        # Domain adaptation
        use_da: bool = True,
        w_consistency: float = 0.2,
        pseudo_thresh: float = 0.8,
        lr: float = 2e-4,
        weight_decay: float = 1e-5,
    ):
        super().__init__()
        self.save_hyperparameters()

        self.model = LensGNN(
            in_ch=in_ch, node_dim=node_dim, n_layers=n_layers,
            k=k, p_drop=p_drop, predict_logvar=predict_logvar
        )
        self.verif_head = LatentVerificationHead(use_uncertainty=predict_logvar)
        self.physics_loss = LensPhysicsLoss(w_poisson=w_physics, w_deflection=w_physics, robust_delta=0.0)

        self.lr = float(lr)
        self.weight_decay = float(weight_decay)

    def configure_optimizers(self):
        opt = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)
        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=50)
        return {"optimizer": opt, "lr_scheduler": sch}

    @staticmethod
    def gaussian_nll(pred: Tensor, target: Tensor, logvar: Optional[Tensor]) -> Tensor:
        if logvar is None:
            return (pred - target).pow(2).mean()
        return 0.5 * (logvar.exp() * (pred - target).pow(2) + logvar).mean()

    def forward(self, x: Tensor) -> Dict[str, Tensor]:
        return self.model(x)

    def training_step(self, batch: Dict[str, Tensor], batch_idx: int) -> Tensor:
        """
        batch can contain:
          - 'image': [B,C,H,W]
          - optional labels:
              'kappa': [B,1,H',W'], 'alpha': [B,2,H',W'], or
              'label': [B] for verification (binary)
          - for DA: optional 'image_strong' (strongly augmented view)
        """
        x = batch["image"]
        out = self.model(x)

        # Supervised reconstruction losses (optional)
        loss_sup = torch.zeros((), device=self.device)
        if "kappa" in batch:
            # Downsample target to match GNN maps if needed
            target_kappa = nn.functional.interpolate(batch["kappa"], size=out["kappa"].shape[-2:], mode="bilinear", align_corners=False)
            loss_sup = loss_sup + self.hparams.w_kappa * self.gaussian_nll(out["kappa"], target_kappa, out.get("kappa_logvar"))
        if "alpha" in batch:
            target_alpha = nn.functional.interpolate(batch["alpha"], size=out["alpha"].shape[-2:], mode="bilinear", align_corners=False)
            loss_sup = loss_sup + self.hparams.w_alpha * self.gaussian_nll(out["alpha"], target_alpha, out.get("alpha_logvar"))

        # Physics losses
        phys = self.physics_loss(out["psi"], out["kappa"], out["alpha"])
        loss_phys = phys["loss_physics"]

        # Verification head (optional label)
        loss_verif = torch.zeros((), device=self.device)
        if "label" in batch:
            verif_logit = self.verif_head(out)
            loss_verif = nn.functional.binary_cross_entropy_with_logits(verif_logit, batch["label"].float())

        # Domain adaptation: consistency on unlabeled images
        loss_cons = torch.zeros((), device=self.device)
        if self.hparams.use_da and "image_strong" in batch:
            out_w = out  # weak view already computed
            out_s = self.model(batch["image_strong"])
            # L2 consistency on κ and α (stop-grad on weak as pseudo-target)
            with torch.no_grad():
                kappa_t = out_w["kappa"]
                alpha_t = out_w["alpha"]
                # optional confidence mask via variance / temperature
                if out_w.get("kappa_logvar") is not None:
                    conf = (-out_w["kappa_logvar"]).clamp(min=-10, max=10).sigmoid()  # proxy
                    mask = (conf > self.hparams.pseudo_thresh).float()
                else:
                    mask = torch.ones_like(kappa_t)
            loss_cons = self.hparams.w_consistency * (
                ((out_s["kappa"] - kappa_t).pow(2) * mask).mean() +
                ((out_s["alpha"] - alpha_t).pow(2)).mean()
            )

        loss = loss_sup + loss_phys + loss_verif + loss_cons

        self.log_dict({
            "train/loss": loss,
            "train/loss_sup": loss_sup,
            "train/loss_phys": loss_phys,
            "train/loss_verif": loss_verif,
            "train/loss_cons": loss_cons,
            "train/loss_poisson": phys["loss_poisson"],
            "train/loss_deflect": phys["loss_deflection"],
        }, prog_bar=True, on_step=True, on_epoch=True)
        return loss

    def validation_step(self, batch: Dict[str, Tensor], batch_idx: int) -> None:
        x = batch["image"]
        out = self.model(x)
        phys = self.physics_loss(out["psi"], out["kappa"], out["alpha"])
        self.log("val/loss_phys", phys["loss_physics"], prog_bar=True)
```

Edit: src/models/ensemble/registry.py (register LensGNN)
```python
# Add near other registrations
register_model(
    name="lens_gnn",
    backbone_class=None,  # constructed via unified factory or a small adapter
    backbone_kwargs={},
    feature_dim=0,        # not used here
    input_size=224,
    description="Graph neural network reconstructing psi/kappa/alpha from images"
)
```

Edit: src/models/unified_factory.py (support lens_gnn)
```python
# Inside _build_model_registry()
"lens_gnn": {
    "type": "single",
    "supports_physics": True,
    "input_size": 224,
    "outputs": "latent_maps",
    "description": "LensGNN: reconstructs psi, kappa, alpha from multi-band images",
},

# Inside _create_single_model()
if config.architecture == "lens_gnn":
    from .gnn.lens_gnn_system import LensGNNSystem
    return LensGNNSystem(
        in_ch=config.bands,
        node_dim=int(config.extra.get("node_dim", 128)),
        n_layers=int(config.extra.get("n_layers", 4)),
        k=int(config.extra.get("k", 8)),
        p_drop=float(config.extra.get("p_drop", 0.1)),
        predict_logvar=bool(config.extra.get("predict_logvar", True)),
        w_kappa=float(config.extra.get("w_kappa", 1.0)),
        w_alpha=float(config.extra.get("w_alpha", 1.0)),
        w_physics=float(config.extra.get("w_physics", 1.0)),
        use_da=bool(config.extra.get("use_da", True)),
        w_consistency=float(config.extra.get("w_consistency", 0.2)),
        pseudo_thresh=float(config.extra.get("pseudo_thresh", 0.8)),
        lr=float(config.extra.get("lr", 2e-4)),
        weight_decay=float(config.extra.get("weight_decay", 1e-5)),
    )
```

New file: configs/lens_gnn.yaml
```yaml
model:
  type: single
  architecture: lens_gnn
  bands: 3
  extra:
    node_dim: 128
    n_layers: 4
    k: 8
    p_drop: 0.1
    predict_logvar: true
    w_kappa: 1.0
    w_alpha: 1.0
    w_physics: 1.0
    use_da: true
    w_consistency: 0.2
    pseudo_thresh: 0.8
    lr: 0.0002
    weight_decay: 0.00001

trainer:
  epochs: 50
  batch_size: 32
  img_size: 224
  num_workers: 4
```

New tests: tests/test_lens_gnn.py
```python
import torch
import pytest

from src.models.gnn.lens_gnn import LensGNN
from src.physics.lens_physics import LensPhysicsLoss, grad2d, laplacian2d

def test_forward_shapes():
    model = LensGNN(in_ch=3, node_dim=64, n_layers=2, k=4, predict_logvar=True)
    x = torch.randn(2, 3, 224, 224)
    out = model(x)
    assert out["psi"].shape[1:] == (1, out["psi"].shape[-2], out["psi"].shape[-1])
    assert out["kappa"].shape[1] == 1
    assert out["alpha"].shape[1] == 2
    assert "kappa_logvar" in out and "alpha_logvar" in out

def test_physics_loss_decreases_trivial():
    # Construct psi and derive alpha, kappa; physics loss should be near zero.
    B, H, W = 1, 56, 56
    psi = torch.randn(B, 1, H, W) * 0.01
    gx, gy = grad2d(psi)
    kappa = 0.5 * laplacian2d(psi)  # ensures Poisson relation
    alpha = torch.cat([gx, gy], dim=1)
    loss = LensPhysicsLoss()(psi, kappa, alpha)
    assert loss["loss_physics"].item() < 1e-4

def test_mc_dropout_variability():
    model = LensGNN(in_ch=3, node_dim=64, n_layers=2, k=4, predict_logvar=False)
    model.train()  # MC-dropout
    x = torch.randn(1, 3, 224, 224)
    out1 = model(x)["kappa"]
    out2 = model(x)["kappa"]
    assert (out1 - out2).abs().mean().item() > 0.0
```

Optional: domain adaptation test (consistency term is finite even without labels).

How to train/evaluate
- Train (Lightning): use your existing Lightning entry with the new config.
  - Example: `python src/lit_train.py --config configs/lens_gnn.yaml`
- Ensemble with existing detector backbones:
  - Build heterogeneous ensemble including `lens_gnn` via `unified_factory`, then apply your existing temperature scaling at evaluation.

Notes
- Minimal deps: no PyG; custom kNN+message passing is implemented in pure PyTorch.
- Uncertainty: MC-dropout supported by Dropout layers; optional Gaussian NLL via predicted log-variance.
- Physics: Poisson and deflection constraints are enforced via `LensPhysicsLoss` and logged.
- Domain adaptation: consistency on weak/strong views and simple pseudo-label gating.

If you want, I can also add a small adapter to fuse CNN/ViT global features with the `LatentVerificationHead` for joint decision-making, or wire `LensGNNSystem` into an existing ensemble config file.


second repost:
Now I'll create a comprehensive integration plan with all the implementation files, following best practices and state-of-the-art methodologies based on the literature.

## Optimal LensGNN Integration Plan for Gravitational Lensing Detection

Based on extensive research in physics-informed graph neural networks, weak lensing mass reconstruction, semi-supervised domain adaptation, and uncertainty quantification, this integration plan combines cutting-edge methodologies with production-ready software engineering practices.[1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16]

### Executive Summary

This plan integrates a **Physics-Informed Graph Neural Network (LensGNN)** into your existing machine lensing project to reconstruct surface mass density (κ), deflection field (α), and lens potential (ψ) from multi-band images. The architecture enforces gravitational lensing physics via differentiable Poisson equations, supports domain adaptation for real survey data, and provides calibrated uncertainty estimates—addressing key challenges identified in recent literature.[7][8][9][12]

**Key innovations over baseline approaches:**
- Physics-informed message passing with learned attention guided by gradient alignment[3][5]
- Heteroscedastic uncertainty with β-weighted NLL loss to prevent variance collapse[17][18]
- Semi-supervised consistency regularization for unlabeled real observations[10][12][19]
- Graph construction from both regular grids and superpixels (SLIC)[20][21][22]
- Temperature scaling calibration adapted for graph-structured predictions[11][14][23]

---

### 1. Architecture & Design Principles

**Foundation:** Build on proven weak-lensing CNN architectures and recent physics-informed GNN work.[2][4][5][6][8][1][3][7]

**Core Components:**
1. **Graph Builder** – Converts images to graph representations (grid/superpixel nodes)
2. **Physics Operators** – Differentiable finite-difference gradient/divergence/Laplacian[24][25][26]
3. **LensGNN Model** – Message-passing network with physics-guided attention[27][28][3]
4. **Multi-task Heads** – Predict κ, ψ, α with heteroscedastic uncertainty[18][29][17]
5. **Physics-Informed Loss** – Enforce Poisson relation, smoothness, and consistency[8][7]
6. **Lightning Module** – Production training with DDP, AMP, callbacks[15][16][30]
7. **Semi-Supervised DataModule** – Mixed sim/real batches with consistency losses[12][31][32][33][10]
8. **Calibration & Evaluation** – Temperature scaling, ECE, reliability plots[14][23][11]

***

### 2. Detailed Module Specifications

#### 2.1 Graph Construction (`mlensing/gnn/graph_builder.py`)

**Literature basis:** Grid graphs are standard in physics-informed GNNs, while superpixels reduce computational cost.[5][21][22][3][20]

**Implementation:**
```python
"""
Graph construction from astronomical images.

Supports:
- Regular grid graphs (fast, uniform coverage)
- SLIC superpixel graphs (adaptive, fewer nodes)
- Multi-band feature aggregation
- PSF-aware local statistics
"""
import torch
import numpy as np
from typing import Tuple, Optional, Literal
from skimage.segmentation import slic
from skimage.measure import regionprops
try:
    from torch_geometric.data import Data, Batch
    HAS_PYG = True
except ImportError:
    HAS_PYG = False

def build_grid_graph(
    images: torch.Tensor,  # (B, C, H, W)
    backbone_feats: Optional[torch.Tensor] = None,  # (B, F, H', W')
    patch_size: int = 2,
    connectivity: Literal["4", "8", "8+ring"] = "8",
    psf_sigma: Optional[float] = None,
) -> Batch:
    """
    Build regular grid graph from images.
    
    Args:
        images: Multi-band images
        backbone_feats: Optional CNN/ViT features to fuse
        patch_size: Aggregate S×S pixels per node (reduces resolution)
        connectivity: Edge topology (4-neighbors, 8-neighbors, or 8+ring for angular support)
        psf_sigma: If provided, compute PSF-aware Laplacian features
        
    Returns:
        PyG Batch with:
            x: Node features (B*N, D) - local stats + backbone feats + band ratios
            edge_index: (2, E)
            edge_attr: (E, edge_dim) - relative coords, distance, gradient alignment
            batch: (B*N,) - batch assignment
            meta: dict with H, W, patch_size for reconstruction
    """
    B, C, H, W = images.shape
    device = images.device
    
    # Patch pooling to reduce nodes
    if patch_size > 1:
        images_pooled = torch.nn.functional.avg_pool2d(images, patch_size)
        H_grid, W_grid = H // patch_size, W // patch_size
    else:
        images_pooled = images
        H_grid, W_grid = H, W
    
    N = H_grid * W_grid
    graphs = []
    
    for b in range(B):
        img = images_pooled[b]  # (C, H_grid, W_grid)
        
        # --- Node features ---
        # Local statistics per patch
        node_feats = []
        for i in range(H_grid):
            for j in range(W_grid):
                patch = img[:, i, j]  # (C,)
                # Mean, std, gradients across bands
                mean = patch.mean()
                std = patch.std()
                # Approximate gradient magnitude
                if i > 0 and j > 0 and i < H_grid-1 and j < W_grid-1:
                    gx = (img[:, i, j+1] - img[:, i, j-1]).abs().mean()
                    gy = (img[:, i+1, j] - img[:, i-1, j]).abs().mean()
                    grad_mag = (gx**2 + gy**2).sqrt()
                else:
                    grad_mag = torch.tensor(0.0, device=device)
                
                # Band ratios (for color consistency checks)
                if C >= 3:
                    ratio_01 = patch[0] / (patch[1] + 1e-8)
                    ratio_12 = patch[1] / (patch[2] + 1e-8)
                    feats = torch.stack([mean, std, grad_mag, ratio_01, ratio_12] + list(patch))
                else:
                    feats = torch.stack([mean, std, grad_mag] + list(patch))
                
                node_feats.append(feats)
        
        node_feats = torch.stack(node_feats)  # (N, D_local)
        
        # Fuse backbone features if provided
        if backbone_feats is not None:
            bb_feat = backbone_feats[b]  # (F, H', W')
            # Upsample to grid resolution
            bb_feat_up = torch.nn.functional.interpolate(
                bb_feat.unsqueeze(0), size=(H_grid, W_grid), mode='bilinear', align_corners=False
            ).squeeze(0)  # (F, H_grid, W_grid)
            bb_feat_flat = bb_feat_up.permute(1, 2, 0).reshape(N, -1)  # (N, F)
            node_feats = torch.cat([node_feats, bb_feat_flat], dim=1)
        
        # --- Edge construction ---
        edge_index = []
        edge_attr = []
        
        for i in range(H_grid):
            for j in range(W_grid):
                src = i * W_grid + j
                neighbors = []
                
                # 4-connected
                if j < W_grid - 1:
                    neighbors.append((i, j+1))  # right
                if i < H_grid - 1:
                    neighbors.append((i+1, j))  # down
                
                # 8-connected
                if connectivity in ["8", "8+ring"]:
                    if i < H_grid-1 and j < W_grid-1:
                        neighbors.append((i+1, j+1))  # down-right
                    if i < H_grid-1 and j > 0:
                        neighbors.append((i+1, j-1))  # down-left
                
                # Ring connections (2-hop) for better angular support
                if connectivity == "8+ring":
                    if j < W_grid - 2:
                        neighbors.append((i, j+2))
                    if i < H_grid - 2:
                        neighbors.append((i+2, j))
                
                for ni, nj in neighbors:
                    tgt = ni * W_grid + nj
                    edge_index.append([src, tgt])
                    edge_index.append([tgt, src])  # undirected
                    
                    # Edge attributes
                    dx = (nj - j) * patch_size
                    dy = (ni - i) * patch_size
                    dist = (dx**2 + dy**2).sqrt()
                    
                    # Gradient alignment: dot product of local gradients
                    src_grad = node_feats[src, 2]  # grad_mag at src
                    tgt_grad = node_feats[tgt, 2]
                    grad_align = src_grad * tgt_grad  # simplified
                    
                    # Photometric contrast
                    photo_contrast = (node_feats[src, 0] - node_feats[tgt, 0]).abs()
                    
                    edge_feat = torch.tensor([dx, dy, dist, grad_align, photo_contrast], device=device)
                    edge_attr.append(edge_feat)
                    edge_attr.append(edge_feat)  # symmetric
        
        edge_index = torch.tensor(edge_index, dtype=torch.long, device=device).T  # (2, E)
        edge_attr = torch.stack(edge_attr)  # (E, edge_dim)
        
        # Create PyG Data
        if HAS_PYG:
            graph = Data(x=node_feats, edge_index=edge_index, edge_attr=edge_attr)
        else:
            # Fallback: store as dict
            graph = {
                'x': node_feats, 
                'edge_index': edge_index, 
                'edge_attr': edge_attr,
                'num_nodes': N
            }
        
        graphs.append(graph)
    
    # Batch graphs
    if HAS_PYG:
        batch = Batch.from_data_list(graphs)
    else:
        # Manual batching
        batch = _manual_batch(graphs)
    
    # Store metadata for reconstruction
    batch.meta = {'H': H_grid, 'W': W_grid, 'patch_size': patch_size, 'B': B}
    
    return batch


def build_superpixel_graph(
    images: torch.Tensor,
    n_segments: int = 200,
    compactness: float = 10.0,
    sigma: float = 1.0,
    backbone_feats: Optional[torch.Tensor] = None,
) -> Batch:
    """
    Build superpixel graph using SLIC.
    
    Nodes: superpixels
    Edges: adjacency from region borders
    Features: mean color, std, morphology stats, pooled backbone features
    """
    B, C, H, W = images.shape
    device = images.device
    graphs = []
    
    for b in range(B):
        img_np = images[b].permute(1, 2, 0).cpu().numpy()  # (H, W, C)
        
        # SLIC segmentation
        segments = slic(
            img_np, 
            n_segments=n_segments, 
            compactness=compactness, 
            sigma=sigma,
            start_label=0,
            convert2lab=(C >= 3)
        )
        
        # Extract region properties
        props = regionprops(segments + 1, intensity_image=img_np.mean(axis=2))
        n_sp = len(props)
        
        # Node features
        node_feats = []
        for prop in props:
            coords = prop.coords  # (N_pixels, 2)
            intensities = img_np[coords[:, 0], coords[:, 1], :]  # (N_pixels, C)
            
            mean_color = intensities.mean(axis=0)
            std_color = intensities.std(axis=0)
            area = prop.area
            eccentricity = prop.eccentricity
            
            feats = np.concatenate([mean_color, std_color, [area, eccentricity]])
            node_feats.append(feats)
        
        node_feats = torch.tensor(np.array(node_feats), dtype=torch.float32, device=device)
        
        # Pool backbone features per superpixel
        if backbone_feats is not None:
            bb = backbone_feats[b]  # (F, H', W')
            bb_pooled = []
            for prop in props:
                coords = prop.coords
                # Map to backbone resolution
                coords_scaled = (coords / np.array([H, W]) * np.array(bb.shape[1:])).astype(int)
                coords_scaled = np.clip(coords_scaled, 0, [bb.shape[1]-1, bb.shape[2]-1])
                bb_vals = bb[:, coords_scaled[:, 0], coords_scaled[:, 1]]  # (F, N_pixels)
                bb_pooled.append(bb_vals.mean(dim=1))
            bb_pooled = torch.stack(bb_pooled)  # (n_sp, F)
            node_feats = torch.cat([node_feats, bb_pooled], dim=1)
        
        # Build edges from adjacency
        edge_index = []
        # Simple adjacency: check if superpixels share boundary
        segments_tensor = torch.tensor(segments, dtype=torch.long, device=device)
        for i in range(H-1):
            for j in range(W-1):
                sp_curr = segments_tensor[i, j]
                # Check right and down neighbors
                sp_right = segments_tensor[i, j+1]
                sp_down = segments_tensor[i+1, j]
                if sp_curr != sp_right:
                    edge_index.append([sp_curr.item(), sp_right.item()])
                if sp_curr != sp_down:
                    edge_index.append([sp_curr.item(), sp_down.item()])
        
        edge_index = torch.tensor(edge_index, dtype=torch.long, device=device).T  # (2, E)
        # Make undirected
        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)
        edge_index = torch.unique(edge_index, dim=1)
        
        # Simple edge attributes: distance between centroids
        edge_attr = []
        centroids = [torch.tensor(prop.centroid, device=device) for prop in props]
        for e in range(edge_index.shape[1]):
            src, tgt = edge_index[:, e]
            c_src, c_tgt = centroids[src], centroids[tgt]
            dist = torch.norm(c_src - c_tgt)
            edge_attr.append(torch.tensor([dist], device=device))
        edge_attr = torch.stack(edge_attr)
        
        if HAS_PYG:
            graph = Data(x=node_feats, edge_index=edge_index, edge_attr=edge_attr)
        else:
            graph = {'x': node_feats, 'edge_index': edge_index, 'edge_attr': edge_attr, 'num_nodes': n_sp}
        
        graphs.append(graph)
    
    if HAS_PYG:
        batch = Batch.from_data_list(graphs)
    else:
        batch = _manual_batch(graphs)
    
    batch.meta = {'mode': 'superpixel', 'n_segments': n_segments, 'B': B}
    return batch


def _manual_batch(graphs):
    """Fallback batching without PyG."""
    # Concatenate node features and track offsets for edge_index
    xs, edge_indices, edge_attrs, batch_vec = [], [], [], []
    offset = 0
    for i, g in enumerate(graphs):
        xs.append(g['x'])
        edge_indices.append(g['edge_index'] + offset)
        edge_attrs.append(g['edge_attr'])
        batch_vec.append(torch.full((g['num_nodes'],), i, dtype=torch.long, device=g['x'].device))
        offset += g['num_nodes']
    
    class BatchDict:
        def __init__(self):
            self.x = torch.cat(xs, dim=0)
            self.edge_index = torch.cat(edge_indices, dim=1)
            self.edge_attr = torch.cat(edge_attrs, dim=0)
            self.batch = torch.cat(batch_vec)
            self.meta = {}
    
    return BatchDict()
```

**Key design decisions:**
- **Grid graphs** (default): Fast, deterministic, uniform coverage; supports patch aggregation to control node count[3][27]
- **Superpixels** (optional): Adaptive to image structure; fewer nodes (~200 vs ~1000s); useful for high-res images[21][22][20]
- **Edge features** include physics-motivated attributes (gradient alignment, photometric contrast) to guide message passing[5][3]
- **Backbone fusion**: Concatenate upsampled CNN/ViT features to nodes for richer representations[7][8]

**Tests** (`tests/test_graph_builder.py`):
```python
import torch
import pytest
from mlensing.gnn.graph_builder import build_grid_graph, build_superpixel_graph

def test_grid_graph_shapes():
    """Verify grid graph produces correct node/edge counts."""
    B, C, H, W = 2, 3, 64, 64
    images = torch.randn(B, C, H, W)
    
    # Patch size 2 → 32×32 grid
    batch = build_grid_graph(images, patch_size=2, connectivity="8")
    
    expected_nodes = B * 32 * 32
    assert batch.x.shape[0] == expected_nodes
    assert batch.edge_index.shape[0] == 2
    assert batch.edge_attr.shape[0] == batch.edge_index.shape[1]
    assert batch.meta['H'] == 32
    assert batch.meta['W'] == 32

def test_superpixel_graph():
    """Check superpixel graph construction."""
    images = torch.randn(1, 3, 128, 128)
    batch = build_superpixel_graph(images, n_segments=100)
    
    # Should have ~100 nodes (approximate)
    assert 80 <= batch.x.shape[0] <= 120
    assert batch.edge_index.shape[0] == 2

def test_backbone_fusion():
    """Ensure backbone features are concatenated correctly."""
    images = torch.randn(1, 3, 64, 64)
    bb_feats = torch.randn(1, 128, 16, 16)  # Lower resolution
    
    batch = build_grid_graph(images, backbone_feats=bb_feats, patch_size=2)
    # Node features should include local stats + 128 backbone dims
    assert batch.x.shape[1] > 10  # At least local stats + some backbone
```

***

#### 2.2 Physics Operators (`mlensing/gnn/physics_ops.py`)

**Literature basis:** Finite-difference operators are standard in physics-informed neural networks for PDEs. Symmetric padding ensures Neumann boundary conditions.[34][25][26]

**Implementation:**
```python
"""
Differentiable physics operators for gravitational lensing.

Implements:
- 2D gradient (∇)
- 2D divergence (∇·)
- 2D Laplacian (∇²)
- Poisson residual (∇²ψ - 2κ)
- Helmholtz projection (enforce irrotationality)

All operators use symmetric padding for Neumann BCs and are fully differentiable.
"""
import torch
import torch.nn.functional as F
from typing import Tuple

def _pad_symmetric(x: torch.Tensor, k: int = 1) -> torch.Tensor:
    """Symmetric (reflect) padding for Neumann boundary conditions."""
    return F.pad(x, (k, k, k, k), mode='reflect')

def gradient2d(field: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    Compute 2D gradient using central finite differences.
    
    Args:
        field: (B, 1, H, W)
    
    Returns:
        gx, gy: (B, 1, H, W) each - gradient components
    """
    assert field.ndim == 4 and field.shape[1] == 1, "Expected (B, 1, H, W)"
    
    f_pad = _pad_symmetric(field, 1)
    
    # Central differences: (f[i+1] - f[i-1]) / 2
    gx = (f_pad[:, :, 1:-1, 2:] - f_pad[:, :, 1:-1, :-2]) * 0.5
    gy = (f_pad[:, :, 2:, 1:-1] - f_pad[:, :, :-2, 1:-1]) * 0.5
    
    return gx, gy

def divergence2d(vec: torch.Tensor) -> torch.Tensor:
    """
    Compute 2D divergence of vector field.
    
    Args:
        vec: (B, 2, H, W) - [vx, vy]
    
    Returns:
        div: (B, 1, H, W)
    """
    assert vec.ndim == 4 and vec.shape[1] == 2
    
    vx = vec[:, 0:1, :, :]  # (B, 1, H, W)
    vy = vec[:, 1:2, :, :]
    
    dvx_dx, _ = gradient2d(vx)
    _, dvy_dy = gradient2d(vy)
    
    return dvx_dx + dvy_dy

def laplacian2d(field: torch.Tensor) -> torch.Tensor:
    """
    Compute 2D Laplacian using 5-point stencil.
    
    Laplacian = ∂²f/∂x² + ∂²f/∂y²
    
    Args:
        field: (B, 1, H, W)
    
    Returns:
        lap: (B, 1, H, W)
    """
    f_pad = _pad_symmetric(field, 1)
    
    center = f_pad[:, :, 1:-1, 1:-1]
    left = f_pad[:, :, 1:-1, :-2]
    right = f_pad[:, :, 1:-1, 2:]
    top = f_pad[:, :, :-2, 1:-1]
    bottom = f_pad[:, :, 2:, 1:-1]
    
    lap = left + right + top + bottom - 4 * center
    
    return lap

def poisson_residual(psi: torch.Tensor, kappa: torch.Tensor, factor: float = 2.0) -> torch.Tensor:
    """
    Compute Poisson equation residual for gravitational lensing.
    
    Lensing equation: ∇²ψ = 2κ
    Residual: ∇²ψ - 2κ  (should be ~0 for valid solutions)
    
    Args:
        psi: Lens potential (B, 1, H, W)
        kappa: Convergence (B, 1, H, W)
        factor: Constant (default 2.0 for standard lensing)
    
    Returns:
        residual: (B, 1, H, W)
    """
    lap_psi = laplacian2d(psi)
    return lap_psi - factor * kappa

def project_irrotational(alpha: torch.Tensor) -> torch.Tensor:
    """
    Project deflection field to be irrotational (curl-free) using Helmholtz decomposition.
    
    For lensing, α should satisfy α = ∇ψ (irrotational).
    This enforces that by computing ψ via Poisson solve and returning ∇ψ.
    
    Note: Simplified version using finite differences. For production, consider FFT-based Poisson solver.
    
    Args:
        alpha: Deflection field (B, 2, H, W)
    
    Returns:
        alpha_proj: Irrotational component (B, 2, H, W)
    """
    # Compute divergence of alpha
    div_alpha = divergence2d(alpha)  # (B, 1, H, W)
    
    # Solve ∇²ψ = ∇·α (Poisson equation) - simplified via iterative relaxation
    # For speed, use single-step approximation: ψ ≈ div_alpha (not exact)
    # Production: use FFT-based solver or multigrid
    psi_approx = div_alpha  # Placeholder
    
    # Compute gradient of ψ
    gx, gy = gradient2d(psi_approx)
    alpha_proj = torch.cat([gx, gy], dim=1)
    
    return alpha_proj

def total_variation(field: torch.Tensor, edge_aware: bool = False, image: torch.Tensor = None) -> torch.Tensor:
    """
    Compute Total Variation regularization (promotes smoothness while preserving edges).
    
    TV = Σ |∇field|
    
    Args:
        field: (B, 1, H, W)
        edge_aware: If True, weight by inverse image gradient (preserve arc features)
        image: (B, C, H, W) - used for edge-aware weighting
    
    Returns:
        tv: scalar
    """
    gx, gy = gradient2d(field)
    grad_mag = torch.sqrt(gx**2 + gy**2 + 1e-8)
    
    if edge_aware and image is not None:
        # Compute image gradient as edge map
        img_gray = image.mean(dim=1, keepdim=True)  # (B, 1, H, W)
        img_gx, img_gy = gradient2d(img_gray)
        img_grad = torch.sqrt(img_gx**2 + img_gy**2 + 1e-8)
        # Weight: inversely proportional to image gradient (low weight at arc edges)
        weight = torch.exp(-img_grad)
        grad_mag = grad_mag * weight
    
    return grad_mag.mean()
```

**Tests** (`tests/test_physics_ops.py`):
```python
import torch
import numpy as np
from mlensing.gnn.physics_ops import gradient2d, divergence2d, laplacian2d, poisson_residual

def test_gradient_sinusoidal():
    """Test gradient on sin(x)*cos(y) field."""
    H, W = 64, 64
    x = torch.linspace(0, 2*np.pi, W).view(1, 1, 1, W)
    y = torch.linspace(0, 2*np.pi, H).view(1, 1, H, 1)
    
    field = torch.sin(x) * torch.cos(y)  # (1, 1, H, W)
    
    gx, gy = gradient2d(field)
    
    # Analytical: ∂f/∂x = cos(x)*cos(y), ∂f/∂y = -sin(x)*sin(y)
    gx_true = torch.cos(x) * torch.cos(y)
    gy_true = -torch.sin(x) * torch.sin(y)
    
    # Check central region (boundaries have padding effects)
    assert torch.allclose(gx[:, :, 10:-10, 10:-10], gx_true[:, :, 10:-10, 10:-10], atol=0.05)
    assert torch.allclose(gy[:, :, 10:-10, 10:-10], gy_true[:, :, 10:-10, 10:-10], atol=0.05)

def test_laplacian_quadratic():
    """Test Laplacian on quadratic field (x² + y²)."""
    H, W = 64, 64
    x = torch.linspace(-1, 1, W).view(1, 1, 1, W)
    y = torch.linspace(-1, 1, H).view(1, 1, H, 1)
    
    field = x**2 + y**2  # (1, 1, H, W)
    lap = laplacian2d(field)
    
    # Analytical: ∇²(x² + y²) = 2 + 2 = 4
    expected = torch.full_like(field, 4.0)
    
    assert torch.allclose(lap[:, :, 5:-5, 5:-5], expected[:, :, 5:-5, 5:-5], atol=0.1)

def test_poisson_residual_sie():
    """Test Poisson residual on Singular Isothermal Ellipsoid (SIE) lens."""
    # SIE: ψ = θ_E * sqrt(x² + q²y²), κ = θ_E / (2*sqrt(x² + q²y²))
    # Should satisfy ∇²ψ = 2κ
    H, W = 128, 128
    theta_E = 1.0
    q = 0.8
    
    x = torch.linspace(-2, 2, W).view(1, 1, 1, W)
    y = torch.linspace(-2, 2, H).view(1, 1, H, 1)
    
    r = torch.sqrt(x**2 + q**2 * y**2 + 1e-4)
    psi = theta_E * r
    kappa = theta_E / (2 * r + 1e-4)
    
    residual = poisson_residual(psi, kappa, factor=2.0)
    
    # Residual should be small (numerical errors from finite differences)
    assert residual.abs().mean() < 0.2, f"Poisson residual too large: {residual.abs().mean()}"
```

***

#### 2.3 LensGNN Model (`mlensing/gnn/lens_gnn.py`)

**Literature basis:** Message-passing GNNs for physics, heteroscedastic uncertainty, MC-dropout.[13][28][29][35][27][17][18][3][5]

**Implementation:**
```python
"""
LensGNN: Physics-Informed Graph Neural Network for gravitational lensing reconstruction.

Architecture:
- Node encoder: MLP on node features
- Message passing: Edge-conditioned graph convolution with physics-guided attention
- Heads: κ, ψ, α with heteroscedastic uncertainty
"""
import torch
import torch.nn as nn
from typing import Dict, Optional, Literal
try:
    from torch_geometric.nn import MessagePassing
    HAS_PYG = True
except ImportError:
    HAS_PYG = False

from .physics_ops import gradient2d

class NodeEncoder(nn.Module):
    """Encode node features to hidden dimension."""
    def __init__(self, in_dim: int, hidden_dim: int, dropout: float = 0.1):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
        )
    
    def forward(self, x):
        return self.mlp(x)

class PhysicsGuidedMessageLayer(MessagePassing if HAS_PYG else nn.Module):
    """
    Message passing layer with physics-guided attention.
    
    Attention is biased by:
    - Gradient alignment (edges along intensity gradients)
    - Radial falloff (distance from node)
    """
    def __init__(self, hidden_dim: int, edge_dim: int, heads: int = 4, dropout: float = 0.1):
        if HAS_PYG:
            super().__init__(aggr='add', node_dim=0)
        else:
            super().__init__()
        
        self.hidden_dim = hidden_dim
        self.heads = heads
        self.head_dim = hidden_dim // heads
        
        # Linear projections for Q, K, V
        self.lin_q = nn.Linear(hidden_dim, hidden_dim)
        self.lin_k = nn.Linear(hidden_dim, hidden_dim)
        self.lin_v = nn.Linear(hidden_dim, hidden_dim)
        
        # Edge feature projection
        self.lin_edge = nn.Linear(edge_dim, heads)
        
        # Output projection
        self.lin_out = nn.Linear(hidden_dim, hidden_dim)
        self.dropout = nn.Dropout(dropout)
        self.norm = nn.LayerNorm(hidden_dim)
    
    def forward(self, x, edge_index, edge_attr):
        """
        Args:
            x: (N, hidden_dim)
            edge_index: (2, E)
            edge_attr: (E, edge_dim)
        """
        if HAS_PYG:
            # PyG message passing
            out = self.propagate(edge_index, x=x, edge_attr=edge_attr)
        else:
            # Manual message passing
            out = self._manual_propagate(x, edge_index, edge_attr)
        
        # Residual connection + normalization
        x = self.norm(x + self.dropout(out))
        return x
    
    def message(self, x_i, x_j, edge_attr):
        """
        Compute messages from source j to target i.
        
        x_i, x_j: (E, hidden_dim)
        edge_attr: (E, edge_dim)
        """
        # Multi-head attention
        Q = self.lin_q(x_i).view(-1, self.heads, self.head_dim)  # (E, heads, head_dim)
        K = self.lin_k(x_j).view(-1, self.heads, self.head_dim)
        V = self.lin_v(x_j).view(-1, self.heads, self.head_dim)
        
        # Attention scores
        attn = (Q * K).sum(dim=-1) / (self.head_dim ** 0.5)  # (E, heads)
        
        # Physics-guided bias: use edge attributes
        # edge_attr includes: [dx, dy, dist, grad_align, photo_contrast]
        edge_bias = self.lin_edge(edge_attr)  # (E, heads)
        attn = attn + edge_bias
        
        attn = torch.softmax(attn, dim=0)  # Normalize per target node
        attn = self.dropout(attn)
        
        # Aggregate values
        msg = (attn.unsqueeze(-1) * V).view(-1, self.hidden_dim)  # (E, hidden_dim)
        return msg
    
    def _manual_propagate(self, x, edge_index, edge_attr):
        """Fallback for non-PyG."""
        src, tgt = edge_index
        x_j = x[src]
        x_i = x[tgt]
        
        # Compute messages
        msg = self.message(x_i, x_j, edge_attr)
        
        # Aggregate by scatter_add
        out = torch.zeros_like(x)
        out.index_add_(0, tgt, msg)
        
        return self.lin_out(out)

class Head(nn.Module):
    """Prediction head with optional heteroscedastic uncertainty."""
    def __init__(self, hidden_dim: int, out_channels: int, heteroscedastic: bool = False):
        super().__init__()
        self.heteroscedastic = heteroscedastic
        self.out_channels = out_channels
        
        if heteroscedastic:
            # Predict both mean and log(variance)
            self.mlp = nn.Sequential(
                nn.Linear(hidden_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Linear(hidden_dim // 2, 2 * out_channels)  # [mu, log_var]
            )
        else:
            self.mlp = nn.Sequential(
                nn.Linear(hidden_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Linear(hidden_dim // 2, out_channels)
            )
    
    def forward(self, x):
        out = self.mlp(x)  # (N, out_channels) or (N, 2*out_channels)
        
        if self.heteroscedastic:
            mu = out[:, :self.out_channels]
            log_var = out[:, self.out_channels:]
            return mu, log_var
        else:
            return out

class LensGNN(nn.Module):
    """
    LensGNN: Graph Neural Network for lensing reconstruction.
    
    Predicts:
    - κ (convergence): surface mass density
    - ψ (potential): lens potential
    - α (deflection): deflection field (can be direct or from ∇ψ)
    """
    def __init__(
        self,
        node_dim: int,
        edge_dim: int,
        hidden_dim: int = 128,
        mp_layers: int = 4,
        heads: int = 4,
        dropout: float = 0.1,
        use_psi_head: bool = True,
        alpha_mode: Literal['grad_from_psi', 'direct', 'both'] = 'both',
        uncertainty: Literal['none', 'heteroscedastic', 'mc_dropout'] = 'heteroscedastic',
        mc_dropout_rate: float = 0.1,
    ):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.use_psi_head = use_psi_head
        self.alpha_mode = alpha_mode
        self.uncertainty = uncertainty
        self.mc_dropout_rate = mc_dropout_rate
        
        # Encoder
        self.encoder = NodeEncoder(node_dim, hidden_dim, dropout)
        
        # Message passing layers
        self.mp_layers = nn.ModuleList([
            PhysicsGuidedMessageLayer(hidden_dim, edge_dim, heads, dropout)
            for _ in range(mp_layers)
        ])
        
        # Prediction heads
        hetero = (uncertainty == 'heteroscedastic')
        self.head_kappa = Head(hidden_dim, 1, heteroscedastic=hetero)
        
        if use_psi_head:
            self.head_psi = Head(hidden_dim, 1, heteroscedastic=False)  # ψ doesn't need uncertainty
        
        if alpha_mode in ['direct', 'both']:
            self.head_alpha = Head(hidden_dim, 2, heteroscedastic=hetero)
        
        # MC-Dropout layers (active during inference if enabled)
        if uncertainty == 'mc_dropout':
            self.dropout_layers = nn.ModuleList([
                nn.Dropout(mc_dropout_rate) for _ in range(mp_layers)
            ])
    
    def forward(self, batch, num_mc_samples: int = 1):
        """
        Args:
            batch: PyG Batch or dict with x, edge_index, edge_attr, meta
            num_mc_samples: Number of MC-dropout forward passes (if using MC-dropout)
        
        Returns:
            outputs: dict with keys:
                - kappa: (B, 1, H, W)
                - psi: (B, 1, H, W) if use_psi_head
                - alpha_from_psi: (B, 2, H, W) if use_psi_head
                - alpha_direct: (B, 2, H, W) if alpha_mode in ['direct', 'both']
                - kappa_var, alpha_var: if uncertainty != 'none'
        """
        x, edge_index, edge_attr = batch.x, batch.edge_index, batch.edge_attr
        meta = batch.meta
        
        # Encode
        h = self.encoder(x)  # (N, hidden_dim)
        
        # Message passing
        for i, mp_layer in enumerate(self.mp_layers):
            h = mp_layer(h, edge_index, edge_attr)
            if self.uncertainty == 'mc_dropout' and self.training:
                h = self.dropout_layers[i](h)
        
        # MC-Dropout inference
        if self.uncertainty == 'mc_dropout' and not self.training and num_mc_samples > 1:
            return self._mc_dropout_forward(h, meta, num_mc_samples, edge_index, edge_attr)
        
        # Single forward pass
        outputs = {}
        
        # Kappa
        if self.uncertainty == 'heteroscedastic':
            kappa_mu, kappa_logvar = self.head_kappa(h)
            kappa_mu = self._reshape_to_grid(kappa_mu, meta, channels=1)
            kappa_var = torch.exp(kappa_logvar)
            kappa_var = self._reshape_to_grid(kappa_var, meta, channels=1)
            outputs['kappa'] = kappa_mu
            outputs['kappa_var'] = kappa_var
        else:
            kappa = self.head_kappa(h)
            kappa = self._reshape_to_grid(kappa, meta, channels=1)
            outputs['kappa'] = kappa
        
        # Psi
        if self.use_psi_head:
            psi = self.head_psi(h)
            psi = self._reshape_to_grid(psi, meta, channels=1)
            outputs['psi'] = psi
            
            # Alpha from gradient of psi
            gx, gy = gradient2d(psi)
            outputs['alpha_from_psi'] = torch.cat([gx, gy], dim=1)
        
        # Direct alpha
        if self.alpha_mode in ['direct', 'both']:
            if self.uncertainty == 'heteroscedastic':
                alpha_mu, alpha_logvar = self.head_alpha(h)
                alpha_mu = self._reshape_to_grid(alpha_mu, meta, channels=2)
                alpha_var = torch.exp(alpha_logvar)
                alpha_var = self._reshape_to_grid(alpha_var, meta, channels=2)
                outputs['alpha_direct'] = alpha_mu
                outputs['alpha_var'] = alpha_var
            else:
                alpha = self.head_alpha(h)
                alpha = self._reshape_to_grid(alpha, meta, channels=2)
                outputs['alpha_direct'] = alpha
        
        return outputs
    
    def _reshape_to_grid(self, node_output, meta, channels):
        """Reshape node predictions back to (B, C, H, W)."""
        if 'mode' in meta and meta['mode'] == 'superpixel':
            # For superpixels, need to map back to pixels (not implemented here - TODO)
            raise NotImplementedError("Superpixel-to-grid reconstruction not implemented.")
        
        B = meta['B']
        H = meta['H']
        W = meta['W']
        
        # Assume grid layout
        N_per_batch = H * W
        node_output_batched = node_output.view(B, H, W, channels).permute(0, 3, 1, 2)
        return node_output_batched
    
    def _mc_dropout_forward(self, h, meta, num_mc_samples, edge_index, edge_attr):
        """Perform multiple forward passes with dropout enabled."""
        # Enable dropout
        for mp_layer in self.mp_layers:
            mp_layer.train()
        for drop in self.dropout_layers:
            drop.train()
        
        kappa_samples = []
        alpha_samples = []
        
        for _ in range(num_mc_samples):
            # Re-run message passing with dropout
            h_mc = h.clone()
            for i, mp_layer in enumerate(self.mp_layers):
                h_mc = mp_layer(h_mc, edge_index, edge_attr)
                h_mc = self.dropout_layers[i](h_mc)
            
            kappa = self.head_kappa(h_mc)
            kappa = self._reshape_to_grid(kappa, meta, channels=1)
            kappa_samples.append(kappa)
            
            if self.alpha_mode in ['direct', 'both']:
                alpha = self.head_alpha(h_mc)
                alpha = self._reshape_to_grid(alpha, meta, channels=2)
                alpha_samples.append(alpha)
        
        # Compute mean and variance
        kappa_stack = torch.stack(kappa_samples)  # (num_mc, B, 1, H, W)
        kappa_mean = kappa_stack.mean(dim=0)
        kappa_var = kappa_stack.var(dim=0)
        
        outputs = {'kappa': kappa_mean, 'kappa_var': kappa_var}
        
        if alpha_samples:
            alpha_stack = torch.stack(alpha_samples)
            alpha_mean = alpha_stack.mean(dim=0)
            alpha_var = alpha_stack.var(dim=0)
            outputs['alpha_direct'] = alpha_mean
            outputs['alpha_var'] = alpha_var
        
        # Reset to eval
        self.eval()
        
        return outputs
```

**Tests** (`tests/test_lens_gnn_shapes.py`):
```python
import torch
from mlensing.gnn.lens_gnn import LensGNN
from mlensing.gnn.graph_builder import build_grid_graph

def test_lensgnn_forward_shapes():
    """Check LensGNN output shapes."""
    B, C, H, W = 2, 3, 64, 64
    images = torch.randn(B, C, H, W)
    batch = build_grid_graph(images, patch_size=2)  # 32×32 grid
    
    node_dim = batch.x.shape[1]
    edge_dim = batch.edge_attr.shape[1]
    
    model = LensGNN(
        node_dim=node_dim,
        edge_dim=edge_dim,
        hidden_dim=64,
        mp_layers=2,
        use_psi_head=True,
        alpha_mode='both',
        uncertainty='heteroscedastic'
    )
    
    outputs = model(batch)
    
    assert outputs['kappa'].shape == (B, 1, 32, 32)
    assert outputs['kappa_var'].shape == (B, 1, 32, 32)
    assert outputs['psi'].shape == (B, 1, 32, 32)
    assert outputs['alpha_from_psi'].shape == (B, 2, 32, 32)
    assert outputs['alpha_direct'].shape == (B, 2, 32, 32)
    assert outputs['alpha_var'].shape == (B, 2, 32, 32)

def test_mc_dropout_inference():
    """Test MC-dropout uncertainty estimation."""
    images = torch.randn(1, 3, 64, 64)
    batch = build_grid_graph(images, patch_size=4)
    
    model = LensGNN(
        node_dim=batch.x.shape[1],
        edge_dim=batch.edge_attr.shape[1],
        hidden_dim=32,
        mp_layers=2,
        uncertainty='mc_dropout',
        mc_dropout_rate=0.2
    )
    model.eval()
    
    outputs = model(batch, num_mc_samples=10)
    
    assert 'kappa' in outputs
    assert 'kappa_var' in outputs
    assert outputs['kappa_var'].mean() > 0  # Should have non-zero variance
```

***

#### 2.4 Physics-Informed Loss (`mlensing/gnn/losses.py`)

**Literature basis:** Physics-informed losses enforce PDE constraints, β-weighted NLL prevents variance collapse, consistency regularization for SSL.[31][32][8][34][10][17][18][7]

```python
"""
Loss functions for LensGNN training.

Combines:
- Physics consistency (Poisson, irrotational deflection)
- Photometric reconstruction (optional)
- Semi-supervised consistency
- Calibrated uncertainty (NLL)
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from .physics_ops import poisson_residual, divergence2d, total_variation

class LensGNNLoss(nn.Module):
    """
    Composite loss for LensGNN.
    
    Components:
    - Poisson: ||∇²ψ - 2κ||₁
    - Alpha consistency: ||α_direct - ∇ψ||₁ (if both heads used)
    - Smoothness: TV(κ) with edge-aware weighting
    - NLL: Heteroscedastic negative log-likelihood (if applicable)
    - SSL consistency: MSE between weak/strong augmented predictions
    - Pseudo-label: High-confidence unlabeled samples
    """
    def __init__(
        self,
        w_poisson: float = 1.0,
        w_alpha: float = 0.2,
        w_tv: float = 0.01,
        w_nll: float = 1.0,
        beta_nll: float = 0.5,  # β-weighting for NLL (Seitzer et al. 2022)
        w_ssl_consistency: float = 0.0,
        w_pseudo: float = 0.0,
        pseudo_threshold: float = 0.9,
        edge_aware_tv: bool = True,
    ):
        super().__init__()
        self.w_poisson = w_poisson
        self.w_alpha = w_alpha
        self.w_tv = w_tv
        self.w_nll = w_nll
        self.beta_nll = beta_nll
        self.w_ssl_consistency = w_ssl_consistency
        self.w_pseudo = w_pseudo
        self.pseudo_threshold = pseudo_threshold
        self.edge_aware_tv = edge_aware_tv
    
    def forward(
        self,
        pred: dict,
        target: dict = None,
        image: torch.Tensor = None,
        pred_weak: dict = None,  # For SSL consistency
        is_labeled: torch.Tensor = None,
    ):
        """
        Args:
            pred: Model predictions (kappa, psi, alpha_*, *_var if applicable)
            target: Ground truth (kappa, alpha) if labeled
            image: Input images (B, C, H, W) for edge-aware TV
            pred_weak: Predictions on weakly augmented unlabeled data
            is_labeled: (B,) boolean mask indicating labeled samples
        
        Returns:
            loss: scalar
            loss_dict: breakdown of components
        """
        device = pred['kappa'].device
        loss = torch.tensor(0.0, device=device)
        loss_dict = {}
        
        # --- Physics consistency ---
        if 'psi' in pred:
            poisson_res = poisson_residual(pred['psi'], pred['kappa'], factor=2.0)
            L_poisson = poisson_res.abs().mean()
            loss += self.w_poisson * L_poisson
            loss_dict['poisson'] = L_poisson.item()
            
            # Alpha consistency
            if 'alpha_direct' in pred:
                L_alpha = (pred['alpha_direct'] - pred['alpha_from_psi']).abs().mean()
                loss += self.w_alpha * L_alpha
                loss_dict['alpha_consistency'] = L_alpha.item()
        
        # --- Smoothness (TV regularization) ---
        if self.w_tv > 0:
            L_tv = total_variation(pred['kappa'], edge_aware=self.edge_aware_tv, image=image)
            loss += self.w_tv * L_tv
            loss_dict['tv'] = L_tv.item()
        
        # --- Supervised loss (if labeled data) ---
        if target is not None and is_labeled is not None and is_labeled.any():
            labeled_mask = is_labeled.view(-1, 1, 1, 1)  # (B, 1, 1, 1)
            
            # Kappa supervision
            if 'kappa' in target:
                kappa_pred = pred['kappa']
                kappa_true = target['kappa']
                
                if 'kappa_var' in pred:
                    # Heteroscedastic NLL with β-weighting
                    var = pred['kappa_var'] + 1e-6
                    L_nll_kappa = self._beta_nll(kappa_pred, kappa_true, var, self.beta_nll)
                    L_nll_kappa = (L_nll_kappa * labeled_mask).sum() / labeled_mask.sum()
                    loss += self.w_nll * L_nll_kappa
                    loss_dict['nll_kappa'] = L_nll_kappa.item()
                else:
                    L_mse_kappa = F.mse_loss(kappa_pred * labeled_mask, kappa_true * labeled_mask, reduction='sum')
                    L_mse_kappa /= labeled_mask.sum()
                    loss += L_mse_kappa
                    loss_dict['mse_kappa'] = L_mse_kappa.item()
            
            # Alpha supervision
            if 'alpha' in target and 'alpha_direct' in pred:
                alpha_pred = pred['alpha_direct']
                alpha_true = target['alpha']
                
                if 'alpha_var' in pred:
                    var = pred['alpha_var'] + 1e-6
                    L_nll_alpha = self._beta_nll(alpha_pred, alpha_true, var, self.beta_nll)
                    labeled_mask_alpha = labeled_mask.expand_as(alpha_pred)
                    L_nll_alpha = (L_nll_alpha * labeled_mask_alpha).sum() / labeled_mask_alpha.sum()
                    loss += self.w_nll * L_nll_alpha
                    loss_dict['nll_alpha'] = L_nll_alpha.item()
                else:
                    L_mse_alpha = F.mse_loss(alpha_pred * labeled_mask.expand_as(alpha_pred), 
                                             alpha_true * labeled_mask.expand_as(alpha_true), 
                                             reduction='sum')
                    L_mse_alpha /= labeled_mask.expand_as(alpha_pred).sum()
                    loss += L_mse_alpha
                    loss_dict['mse_alpha'] = L_mse_alpha.item()
        
        # --- Semi-supervised consistency ---
        if self.w_ssl_consistency > 0 and pred_weak is not None:
            # Consistency between weak and strong augmentations on unlabeled data
            unlabeled_mask = ~is_labeled if is_labeled is not None else torch.ones(pred['kappa'].shape[0], dtype=torch.bool, device=device)
            unlabeled_mask = unlabeled_mask.view(-1, 1, 1, 1)
            
            L_cons_kappa = F.mse_loss(
                pred['kappa'] * unlabeled_mask,
                pred_weak['kappa'].detach() * unlabeled_mask,
                reduction='sum'
            ) / (unlabeled_mask.sum() + 1e-8)
            
            loss += self.w_ssl_consistency * L_cons_kappa
            loss_dict['ssl_consistency'] = L_cons_kappa.item()
        
        # --- Pseudo-labeling ---
        if self.w_pseudo > 0 and pred_weak is not None and is_labeled is not None:
            unlabeled_mask = ~is_labeled
            
            # Use weak predictions as pseudo-labels for high-confidence samples
            # Confidence: inverse of variance (if heteroscedastic) or simply use predictions
            if 'kappa_var' in pred_weak:
                confidence = 1.0 / (pred_weak['kappa_var'].mean(dim=(1,2,3)) + 1e-6)
            else:
                # Use kappa magnitude as proxy for confidence (not ideal)
                confidence = pred_weak['kappa'].abs().mean(dim=(1,2,3))
            
            # Select high-confidence unlabeled samples
            high_conf_mask = (confidence > self.pseudo_threshold) & unlabeled_mask
            
            if high_conf_mask.any():
                high_conf_mask_4d = high_conf_mask.view(-1, 1, 1, 1)
                pseudo_label = pred_weak['kappa'].detach()
                
                L_pseudo = F.mse_loss(
                    pred['kappa'] * high_conf_mask_4d,
                    pseudo_label * high_conf_mask_4d,
                    reduction='sum'
                ) / (high_conf_mask_4d.sum() + 1e-8)
                
                loss += self.w_pseudo * L_pseudo
                loss_dict['pseudo_label'] = L_pseudo.item()
                loss_dict['num_pseudo'] = high_conf_mask.sum().item()
        
        loss_dict['total'] = loss.item()
        return loss, loss_dict
    
    def _beta_nll(self, pred, target, var, beta):
        """
        β-weighted Negative Log-Likelihood (Seitzer et al. 2022).
        
        Standard NLL: 0.5 * log(var) + (pred - target)² / (2*var)
        β-NLL: weight by var^(-beta) to prevent variance collapse
        """
        nll = 0.5 * torch.log(var) + (pred - target)**2 / (2 * var)
        weight = var ** (-beta)
        return (nll * weight).mean()
```

**Tests** (`tests/test_losses_physics_terms.py`):
```python
import torch
from mlensing.gnn.losses import LensGNNLoss

def test_poisson_loss():
    """Check that Poisson residual loss decreases for correct ψ/κ pair."""
    loss_fn = LensGNNLoss(w_poisson=1.0, w_alpha=0.0, w_tv=0.0)
    
    # Toy SIE
    H, W = 64, 64
    x = torch.linspace(-2, 2, W).view(1, 1, 1, W)
    y = torch.linspace(-2, 2, H).view(1, 1, H, 1)
    r = torch.sqrt(x**2 + y**2 + 0.01)
    
    psi = r
    kappa = 0.5 / r
    
    pred = {'psi': psi, 'kappa': kappa}
    loss, loss_dict = loss_fn(pred)
    
    assert loss_dict['poisson'] < 0.5, f"Poisson residual too high: {loss_dict['poisson']}"

def test_beta_nll():
    """Verify β-NLL prevents variance collapse."""
    loss_fn = LensGNNLoss(w_nll=1.0, beta_nll=0.5, w_poisson=0.0, w_tv=0.0)
    
    pred = {
        'kappa': torch.tensor([[[[1.0, 2.0]]]]),
        'kappa_var': torch.tensor([[[[0.1, 0.1]]]]),
    }
    target = {'kappa': torch.tensor([[[[1.5, 2.5]]]])}
    is_labeled = torch.tensor([True])
    
    loss, loss_dict = loss_fn(pred, target, is_labeled=is_labeled)
    
    assert 'nll_kappa' in loss_dict
    assert loss.item() > 0
```

***

### 3. Training & Evaluation Infrastructure

#### 3.1 Lightning Module (`mlensing/gnn/lightning_module.py`)

**Literature basis:** PyTorch Lightning best practices for production ML.[16][30][15]

```python
"""
Lightning Module for LensGNN training.
"""
import pytorch_lightning as pl
import torch
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR

from .lens_gnn import LensGNN
from .losses import LensGNNLoss
from ..evaluation.metrics import compute_reconstruction_metrics, compute_calibration_metrics

class LensGNNLightning(pl.LightningModule):
    def __init__(
        self,
        node_dim: int,
        edge_dim: int,
        hidden_dim: int = 128,
        mp_layers: int = 4,
        lr: float = 3e-4,
        weight_decay: float = 1e-5,
        warmup_steps: int = 2000,
        max_epochs: int = 100,
        loss_weights: dict = None,
        **model_kwargs,
    ):
        super().__init__()
        self.save_hyperparameters()
        
        self.model = LensGNN(
            node_dim=node_dim,
            edge_dim=edge_dim,
            hidden_dim=hidden_dim,
            mp_layers=mp_layers,
            **model_kwargs
        )
        
        loss_weights = loss_weights or {}
        self.loss_fn = LensGNNLoss(**loss_weights)
    
    def forward(self, batch):
        return self.model(batch)
    
    def training_step(self, batch, batch_idx):
        # batch = {graph, target, image, is_labeled, graph_weak (optional)}
        graph = batch['graph']
        target = batch.get('target')
        image = batch.get('image')
        is_labeled = batch.get('is_labeled')
        graph_weak = batch.get('graph_weak')  # For SSL
        
        pred = self(graph)
        
        pred_weak = None
        if graph_weak is not None:
            with torch.no_grad():
                pred_weak = self(graph_weak)
        
        loss, loss_dict = self.loss_fn(
            pred, target, image, pred_weak, is_labeled
        )
        
        # Logging
        for k, v in loss_dict.items():
            self.log(f'train/{k}', v, on_step=True, on_epoch=True, prog_bar=(k=='total'))
        
        return loss
    
    def validation_step(self, batch, batch_idx):
        graph = batch['graph']
        target = batch.get('target')
        image = batch.get('image')
        is_labeled = batch.get('is_labeled', torch.ones(graph.meta['B'], dtype=torch.bool))
        
        pred = self(graph)
        
        # Compute loss
        loss, loss_dict = self.loss_fn(pred, target, image, is_labeled=is_labeled)
        
        for k, v in loss_dict.items():
            self.log(f'val/{k}', v, on_epoch=True, sync_dist=True)
        
        # Metrics (only on labeled)
        if target is not None and is_labeled.any():
            metrics = compute_reconstruction_metrics(
                pred['kappa'][is_labeled],
                target['kappa'][is_labeled],
                pred['alpha_direct'][is_labeled] if 'alpha_direct' in pred else None,
                target.get('alpha'),
            )
            for k, v in metrics.items():
                self.log(f'val/{k}', v, on_epoch=True, sync_dist=True)
            
            # Calibration metrics (if uncertainty available)
            if 'kappa_var' in pred:
                cal_metrics = compute_calibration_metrics(
                    pred['kappa'][is_labeled],
                    target['kappa'][is_labeled],
                    pred['kappa_var'][is_labeled],
                )
                for k, v in cal_metrics.items():
                    self.log(f'val/cal_{k}', v, on_epoch=True, sync_dist=True)
        
        return loss
    
    def configure_optimizers(self):
        optimizer = AdamW(
            self.parameters(),
            lr=self.hparams.lr,
            weight_decay=self.hparams.weight_decay,
        )
        
        # Warmup + Cosine decay
        warmup_scheduler = LinearLR(
            optimizer,
            start_factor=0.01,
            end_factor=1.0,
            total_iters=self.hparams.warmup_steps,
        )
        
        cosine_scheduler = CosineAnnealingLR(
            optimizer,
            T_max=self.hparams.max_epochs - self.hparams.warmup_steps,
            eta_min=1e-6,
        )
        
        scheduler = SequentialLR(
            optimizer,
            schedulers=[warmup_scheduler, cosine_scheduler],
            milestones=[self.hparams.warmup_steps],
        )
        
        return {
            'optimizer': optimizer,
            'lr_scheduler': {
                'scheduler': scheduler,
                'interval': 'step',
            },
        }
```

***

#### 3.2 DataModule (`mlensing/gnn/datamodules.py`)

**Literature basis:** Semi-supervised learning with consistency regularization.[32][10][12][31]

```python
"""
Lightning DataModule for LensGNN.

Supports:
- Simulated data (labeled κ, α)
- Real survey data (unlabeled)
- SSL augmentations (weak/strong)
"""
import pytorch_lightning as pl
from torch.utils.data import DataLoader, Dataset
import torch
from typing import Optional

from .graph_builder import build_grid_graph
from ..datasets.augmentations import WeakAugmentation, StrongAugmentation

class LensGNNDataModule(pl.LightningDataModule):
    def __init__(
        self,
        sim_train_root: str,
        sim_val_root: str,
        real_unlabeled_root: Optional[str] = None,
        batch_size: int = 8,
        num_workers: int = 4,
        patch_size: int = 2,
        connectivity: str = "8",
        ssl_ratio: float = 0.5,  # Fraction of unlabeled in each batch
        use_ssl: bool = False,
    ):
        super().__init__()
        self.save_hyperparameters()
        
        self.sim_train_root = sim_train_root
        self.sim_val_root = sim_val_root
        self.real_unlabeled_root = real_unlabeled_root
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.patch_size = patch_size
        self.connectivity = connectivity
        self.ssl_ratio = ssl_ratio
        self.use_ssl = use_ssl
    
    def setup(self, stage: Optional[str] = None):
        if stage == 'fit' or stage is None:
            # Simulated labeled data
            self.train_sim = LensDataset(
                self.sim_train_root,
                labeled=True,
                augment=True,
            )
            
            # Real unlabeled data (if using SSL)
            if self.use_ssl and self.real_unlabeled_root:
                self.train_real = LensDataset(
                    self.real_unlabeled_root,
                    labeled=False,
                    augment=True,
                )
                # Mixed dataset
                self.train_dataset = MixedDataset(
                    self.train_sim,
                    self.train_real,
                    ssl_ratio=self.ssl_ratio,
                )
            else:
                self.train_dataset = self.train_sim
            
            self.val_dataset = LensDataset(
                self.sim_val_root,
                labeled=True,
                augment=False,
            )
    
    def train_dataloader(self):
        return DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=self.num_workers,
            collate_fn=self.collate_fn,
            pin_memory=True,
        )
    
    def val_dataloader(self):
        return DataLoader(
            self.val_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers,
            collate_fn=self.collate_fn,
            pin_memory=True,
        )
    
    def collate_fn(self, batch_list):
        """
        Collate function to build graphs from image batches.
        
        batch_list: list of dicts with keys: image, kappa, alpha, is_labeled, image_weak (if SSL)
        
        Returns: dict with graph, target, image, is_labeled, graph_weak
        """
        images = torch.stack([b['image'] for b in batch_list])
        is_labeled = torch.tensor([b['is_labeled'] for b in batch_list])
        
        # Build graph
        graph = build_grid_graph(
            images,
            patch_size=self.patch_size,
            connectivity=self.connectivity,
        )
        
        # Target (only for labeled)
        target = None
        if is_labeled.any():
            kappa_list = [b['kappa'] for b in batch_list if b['is_labeled']]
            alpha_list = [b.get('alpha') for b in batch_list if b['is_labeled']]
            
            if kappa_list:
                target = {'kappa': torch.stack(kappa_list)}
                if alpha_list and alpha_list[0] is not None:
                    target['alpha'] = torch.stack(alpha_list)
        
        # SSL: weak augmentation graph
        graph_weak = None
        if self.use_ssl and any('image_weak' in b for b in batch_list):
            images_weak = torch.stack([b.get('image_weak', b['image']) for b in batch_list])
            graph_weak = build_grid_graph(images_weak, patch_size=self.patch_size, connectivity=self.connectivity)
        
        return {
            'graph': graph,
            'target': target,
            'image': images,
            'is_labeled': is_labeled,
            'graph_weak': graph_weak,
        }

class LensDataset(Dataset):
    """Dataset for lensing images."""
    def __init__(self, root, labeled=True, augment=False):
        # TODO: Implement actual data loading from root
        # Placeholder
        self.root = root
        self.labeled = labeled
        self.augment = augment
        self.weak_aug = WeakAugmentation() if augment else None
        self.strong_aug = StrongAugmentation() if augment else None
        
        # Mock data
        self.length = 100
    
    def __len__(self):
        return self.length
    
    def __getitem__(self, idx):
        # Mock: load image, kappa, alpha
        image = torch.randn(3, 128, 128)
        kappa = torch.randn(1, 128, 128) if self.labeled else None
        alpha = torch.randn(2, 128, 128) if self.labeled else None
        
        # Augment
        if self.augment:
            image_weak = self.weak_aug(image) if self.weak_aug else image
            image = self.strong_aug(image) if self.strong_aug else image
        else:
            image_weak = None
        
        return {
            'image': image,
            'image_weak': image_weak,
            'kappa': kappa,
            'alpha': alpha,
            'is_labeled': self.labeled,
        }

class MixedDataset(Dataset):
    """Mix labeled and unlabeled datasets."""
    def __init__(self, labeled_dataset, unlabeled_dataset, ssl_ratio=0.5):
        self.labeled = labeled_dataset
        self.unlabeled = unlabeled_dataset
        self.ssl_ratio = ssl_ratio
        self.length = max(len(labeled_dataset), int(len(unlabeled_dataset) / ssl_ratio))
    
    def __len__(self):
        return self.length
    
    def __getitem__(self, idx):
        # Randomly sample from labeled or unlabeled
        if torch.rand(1).item() < self.ssl_ratio:
            # Unlabeled
            idx_u = idx % len(self.unlabeled)
            return self.unlabeled[idx_u]
        else:
            # Labeled
            idx_l = idx % len(self.labeled)
            return self.labeled[idx_l]
```

***

### 4. Evaluation & Calibration

#### 4.1 Metrics (`mlensing/evaluation/metrics.py`)

```python
"""
Metrics for lensing reconstruction and uncertainty calibration.
"""
import torch
import numpy as np
from scipy.stats import spearmanr

def compute_reconstruction_metrics(kappa_pred, kappa_true, alpha_pred=None, alpha_true=None):
    """
    Compute reconstruction quality metrics.
    
    Returns:
        dict with MAE, MSE, SSIM for κ and α
    """
    metrics = {}
    
    # Kappa
    metrics['kappa_mae'] = (kappa_pred - kappa_true).abs().mean().item()
    metrics['kappa_mse'] = ((kappa_pred - kappa_true) ** 2).mean().item()
    # SSIM (simplified)
    metrics['kappa_ssim'] = ssim_torch(kappa_pred, kappa_true).item()
    
    # Alpha
    if alpha_pred is not None and alpha_true is not None:
        metrics['alpha_mae'] = (alpha_pred - alpha_true).abs().mean().item()
        metrics['alpha_mse'] = ((alpha_pred - alpha_true) ** 2).mean().item()
    
    return metrics

def compute_calibration_metrics(pred, target, var):
    """
    Compute calibration metrics for uncertainty estimates.
    
    Returns:
        NLL, variance-error correlation (Spearman ρ)
    """
    # NLL
    nll = 0.5 * torch.log(var + 1e-6) + (pred - target)**2 / (2 * var + 1e-6)
    nll_mean = nll.mean().item()
    
    # Variance-error correlation
    error = ((pred - target) ** 2).view(-1).cpu().numpy()
    variance = var.view(-1).cpu().numpy()
    
    rho, _ = spearmanr(variance, error)
    
    return {
        'nll': nll_mean,
        'var_error_corr': rho,
    }

def ssim_torch(img1, img2, window_size=11):
    """Simplified SSIM (Structural Similarity Index)."""
    # Simplified version - for production use pytorch-msssim or skimage
    C1 = 0.01 ** 2
    C2 = 0.03 ** 2
    
    mu1 = torch.nn.functional.avg_pool2d(img1, window_size, stride=1, padding=window_size//2)
    mu2 = torch.nn.functional.avg_pool2d(img2, window_size, stride=1, padding=window_size//2)
    
    mu1_sq = mu1 ** 2
    mu2_sq = mu2 ** 2
    mu1_mu2 = mu1 * mu2
    
    sigma1_sq = torch.nn.functional.avg_pool2d(img1 ** 2, window_size, stride=1, padding=window_size//2) - mu1_sq
    sigma2_sq = torch.nn.functional.avg_pool2d(img2 ** 2, window_size, stride=1, padding=window_size//2) - mu2_sq
    sigma12 = torch.nn.functional.avg_pool2d(img1 * img2, window_size, stride=1, padding=window_size//2) - mu1_mu2
    
    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
    
    return ssim_map.mean()
```

***

### 5. Configuration & Entry Points

#### 5.1 Config (`mlensing/gnn/config/lensgnn_default.yaml`)

```yaml
# LensGNN default configuration

model:
  hidden_dim: 128
  mp_layers: 4
  heads: 4
  dropout: 0.1
  use_psi_head: true
  alpha_mode: both  # grad_from_psi | direct | both
  uncertainty: heteroscedastic  # none | heteroscedastic | mc_dropout
  mc_dropout_rate: 0.1

graph:
  mode: grid  # grid | superpixel
  patch_size: 2
  connectivity: "8+ring"  # 4 | 8 | 8+ring
  n_segments: 200  # for superpixel mode

loss:
  w_poisson: 1.0
  w_alpha: 0.2
  w_tv: 0.01
  w_nll: 1.0
  beta_nll: 0.5
  w_ssl_consistency: 0.0  # Enable for SSL
  w_pseudo: 0.0
  pseudo_threshold: 0.9
  edge_aware_tv: true

training:
  lr: 3e-4
  weight_decay: 1e-5
  warmup_steps: 2000
  max_epochs: 100
  batch_size: 8
  gradient_clip_val: 1.0
  precision: 16  # Mixed precision

data:
  sim_train_root: "data/sims/train"
  sim_val_root: "data/sims/val"
  real_unlabeled_root: null  # Set for SSL
  ssl_ratio: 0.5
  use_ssl: false

trainer:
  accelerator: gpu
  devices: 1
  strategy: ddp  # For multi-GPU
  log_every_n_steps: 50
  check_val_every_n_epoch: 1
  enable_checkpointing: true
  logger:
    name: wandb  # or tensorboard
    project: lensgnn
```

#### 5.2 Training Script (`mlensing/gnn/train_lensgnn.py`)

```python
"""
Training script for LensGNN.

Usage:
    python train_lensgnn.py --config configs/lensgnn_default.yaml
"""
import argparse
from pathlib import Path
import yaml
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger

from .lightning_module import LensGNNLightning
from .datamodules import LensGNNDataModule

def main(config_path):
    # Load config
    with open(config_path) as f:
        cfg = yaml.safe_load(f)
    
    # Data
    dm = LensGNNDataModule(
        **cfg['data'],
        batch_size=cfg['training']['batch_size'],
        patch_size=cfg['graph']['patch_size'],
        connectivity=cfg['graph']['connectivity'],
    )
    dm.setup('fit')
    
    # Infer node/edge dims from a sample batch
    sample = next(iter(dm.train_dataloader()))
    node_dim = sample['graph'].x.shape[1]
    edge_dim = sample['graph'].edge_attr.shape[1]
    
    # Model
    model = LensGNNLightning(
        node_dim=node_dim,
        edge_dim=edge_dim,
        **cfg['model'],
        **cfg['training'],
        loss_weights=cfg['loss'],
    )
    
    # Logger
    if cfg['trainer']['logger']['name'] == 'wandb':
        logger = WandbLogger(project=cfg['trainer']['logger']['project'])
    else:
        logger = TensorBoardLogger('logs', name='lensgnn')
    
    # Callbacks
    checkpoint_callback = ModelCheckpoint(
        monitor='val/total',
        mode='min',
        save_top_k=3,
        filename='lensgnn-{epoch:02d}-{val/total:.4f}',
    )
    
    early_stop_callback = EarlyStopping(
        monitor='val/total',
        patience=10,
        mode='min',
    )
    
    lr_monitor = LearningRateMonitor(logging_interval='step')
    
    # Trainer
    trainer = pl.Trainer(
        max_epochs=cfg['training']['max_epochs'],
        gradient_clip_val=cfg['training']['gradient_clip_val'],
        precision=cfg['training']['precision'],
        logger=logger,
        callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],
        **cfg['trainer'],
    )
    
    # Train
    trainer.fit(model, dm)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, required=True, help='Path to config YAML')
    args = parser.parse_args()
    
    main(args.config)
```

***

### 6. Testing & Validation

#### Integration Test (`tests/test_integration_toy_sie.py`)

```python
"""
Integration test: Train LensGNN on toy SIE lenses and verify physics loss convergence.
"""
import torch
import pytest
from mlensing.gnn.lens_gnn import LensGNN
from mlensing.gnn.losses import LensGNNLoss
from mlensing.gnn.graph_builder import build_grid_graph

def generate_toy_sie(B=4, H=64, W=64, theta_E=1.0):
    """Generate SIE lens with known κ, ψ, α."""
    x = torch.linspace(-2, 2, W).view(1, 1, 1, W).expand(B, 1, H, W)
    y = torch.linspace(-2, 2, H).view(1, 1, H, 1).expand(B, 1, H, W)
    
    q = 0.8
    r = torch.sqrt(x**2 + q**2 * y**2 + 0.01)
    
    psi = theta_E * r
    kappa = theta_E / (2 * r)
    
    # Deflection: α = ∇ψ
    gx = theta_E * x / r
    gy = theta_E * q**2 * y / r
    alpha = torch.cat([gx, gy], dim=1)
    
    # Multi-band image (mock)
    image = kappa.expand(B, 3, H, W) + torch.randn(B, 3, H, W) * 0.1
    
    return {
        'image': image,
        'kappa': kappa,
        'psi': psi,
        'alpha': alpha,
    }

@pytest.mark.slow
def test_sie_physics_convergence():
    """Train on SIE data and check Poisson residual decreases."""
    # Generate data
    data = generate_toy_sie(B=8)
    
    # Build graph
    graph = build_grid_graph(data['image'], patch_size=2)
    
    # Model
    model = LensGNN(
        node_dim=graph.x.shape[1],
        edge_dim=graph.edge_attr.shape[1],
        hidden_dim=64,
        mp_layers=3,
        use_psi_head=True,
        alpha_mode='both',
        uncertainty='none',
    )
    
    # Loss
    loss_fn = LensGNNLoss(w_poisson=1.0, w_alpha=0.2, w_tv=0.01, w_nll=0.0)
    
    # Optimizer
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    # Train
    initial_poisson = None
    for step in range(500):
        optimizer.zero_grad()
        
        pred = model(graph)
        target = {
            'kappa': data['kappa'][:, :, ::2, ::2],  # Match grid resolution
            'alpha': data['alpha'][:, :, ::2, ::2],
        }
        is_labeled = torch.ones(8, dtype=torch.bool)
        
        loss, loss_dict = loss_fn(pred, target, data['image'], is_labeled=is_labeled)
        loss.backward()
        optimizer.step()
        
        if step == 0:
            initial_poisson = loss_dict['poisson']
        
        if step % 100 == 0:
            print(f"Step {step}: Poisson={loss_dict['poisson']:.4f}, Total={loss_dict['total']:.4f}")
    
    final_poisson = loss_dict['poisson']
    
    # Check convergence
    assert final_poisson < 0.15, f"Poisson residual did not converge: {final_poisson}"
    assert final_poisson < initial_poisson * 0.5, "Poisson residual should decrease significantly"
```

***

### 7. Acceptance Criteria & Milestones

**Phase 1: Core Physics (Weeks 1-2)**
- ✅ `physics_ops.py` with tests passing on analytic fields
- ✅ `graph_builder.py` (grid mode) with shape tests
- ✅ `lens_gnn.py` forward pass with correct output shapes
- ✅ `losses.py` with Poisson/TV/NLL terms
- ✅ Integration test: SIE toy dataset → Poisson residual < 0.15 in 500 steps

**Phase 2: Training Infrastructure (Weeks 3-4)**
- ✅ Lightning module with DDP, AMP, logging
- ✅ DataModule with sim/real splits
- ✅ Config-driven training script
- ✅ Metrics: MAE, MSE, SSIM for κ/α
- ✅ Sanity check: Train on 100 sim lenses, val MAE < 0.05

**Phase 3: Uncertainty & Calibration (Week 5)**
- ✅ Heteroscedastic heads + β-NLL loss
- ✅ MC-dropout inference mode
- ✅ Calibration metrics: NLL, variance-error correlation (ρ > 0.4 on val)
- ✅ Temperature scaling (optional post-hoc)

**Phase 4: Semi-Supervised Learning (Week 6)**
- ✅ Weak/strong augmentation pipeline
- ✅ Consistency loss + pseudo-labeling
- ✅ Mixed dataloader (labeled + unlabeled)
- ✅ Ablation: SSL improves performance on limited labeled data

**Phase 5: Visualization & Deployment (Week 7)**
- ✅ `viz.py`: κ/α overlays, attention maps, calibration plots
- ✅ Jupyter notebook with qualitative examples
- ✅ Inference script with checkpoint loading
- ✅ Documentation & README

***

### 8. Literature-Driven Best Practices Summary

1. **Physics-Informed Architecture**: Embed lensing equations directly via differentiable operators; use physics-guided attention in message passing.[1][8][3][5][7]

2. **Heteroscedastic Uncertainty with β-NLL**: Prevent variance collapse by weighting NLL loss with `var^(-β)`; β=0.5 is robust across tasks.[29][17][18]

3. **Domain Adaptation**: Use consistency regularization (weak/strong augmentations) and pseudo-labeling for unlabeled real survey data; CORAL/MMD for feature alignment (optional).[9][19][10][12]

4. **Graph Construction**: Grid graphs for uniformity/speed; superpixels for adaptive resolution; include edge features (gradient alignment, distance).[22][27][20][21][3]

5. **Calibration**: Temperature scaling post-training; node-specific temperatures for graph structures; report ECE and reliability diagrams.[23][11][14]

6. **Production ML**: PyTorch Lightning for clean separation of research/engineering code; DDP for multi-GPU; mixed precision (FP16); config-driven experiments.[30][15][16]

7. **Testing**: Unit tests for physics ops (analytic solutions); integration tests on toy lenses (SIE convergence); end-to-end smoke tests.[36][37]

***

### 9. Recommended Sequence of Implementation

1. **physics_ops.py** + unit tests (1 day)
2. **graph_builder.py** (grid mode only) + tests (1 day)
3. **lens_gnn.py** (encoder + message passing + heads, no uncertainty yet) (2 days)
4. **losses.py** (Poisson + TV + MSE, no SSL) (1 day)
5. **Integration test** (toy SIE) to validate physics (1 day)
6. **lightning_module.py** (basic training loop) (1 day)
7. **datamodules.py** (sim data only, no SSL) (1 day)
8. **Config + training script** + sanity check on small dataset (1 day)
9. **Metrics** (reconstruction quality) (0.5 day)
10. **Heteroscedastic uncertainty** (extend heads + β-NLL) (1 day)
11. **MC-dropout** (add dropout layers + multi-pass inference) (0.5 day)
12. **Calibration metrics** + temp scaling (1 day)
13. **SSL augmentations** + consistency loss + pseudo-labeling (2 days)
14. **Superpixel graph mode** (optional) (1 day)
15. **Visualization** (viz.py + notebook) (1 day)
16. **Final eval script** + inference utilities (1 day)

**Total: ~18-20 days** (3-4 weeks with parallelization)

***

### 10. Key Citations & Further Reading

- **Physics-Informed GNNs**:[8][1][3][5][7]
- **Weak Lensing CNNs**:[4][6][2]
- **Heteroscedastic Uncertainty**:[17][18][29]
- **Domain Adaptation**:[19][9][10][12]
- **Graph Calibration**:[11][14][23]
- **PyTorch Lightning**:[15][16][30]
- **Semi-Supervised Learning**:[33][10][31][32]

***

This integration plan synthesizes **state-of-the-art methodologies** from gravitational lensing reconstruction, physics-informed deep learning, uncertainty quantification, and semi-supervised domain adaptation. It provides **production-ready code skeletons**, comprehensive **test coverage**, and a **phased roadmap** to ensure robust, calibrated, and physics-consistent predictions. The architecture is designed to be **composable** with your existing CNN/ViT detectors and **scalable** to large survey datasets via Lightning's distributed training capabilities.

[1](https://arxiv.org/pdf/2507.07541.pdf)
[2](https://arxiv.org/abs/2102.05403)
[3](https://arxiv.org/html/2504.01169v1)
[4](https://arxiv.org/abs/2410.19907)
[5](https://arxiv.org/abs/2504.01169)
[6](https://www.semanticscholar.org/paper/Weak-lensing-Mass-Reconstruction-of-Galaxy-Clusters-Hong-Park/27080179097f4d009ac5aba83f0356a10821a92f)
[7](https://neurips.cc/virtual/2024/100100)
[8](https://ml4physicalsciences.github.io/2024/files/NeurIPS_ML4PS_2024_78.pdf)
[9](https://arxiv.org/abs/2411.03334)
[10](https://arxiv.org/abs/2211.00677)
[11](https://arxiv.org/abs/2506.23782)
[12](https://ml4physicalsciences.github.io/2024/files/NeurIPS_ML4PS_2024_58.pdf)
[13](https://academic.oup.com/mnras/article/517/1/1156/6649832)
[14](https://arxiv.org/abs/2410.09570)
[15](https://www.datacamp.com/tutorial/pytorch-lightning-tutorial)
[16](https://lightning.ai/docs/pytorch/1.6.5/starter/introduction.html)
[17](https://github.com/martius-lab/beta-nll)
[18](https://arxiv.org/html/2406.09262v1)
[19](https://inspirehep.net/files/efd0019571cd7c6ab7686b5001ad50c7)
[20](https://pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/)
[21](https://www.kaggle.com/code/tom99763/super-pixel-graph-construction-for-gnn)
[22](https://github.com/lukasknobel/ShapeGNN)
[23](https://papers.neurips.cc/paper_files/paper/2022/file/5975754c7650dfee0682e06e1fec0522-Paper-Conference.pdf)
[24](https://github.com/rubenwiersma/pointcloud-differential)
[25](https://gpuopen.com/learn/amd-lab-notes/amd-lab-notes-finite-difference-docs-laplacian_part1/)
[26](https://rocm.blogs.amd.com/high-performance-computing/finite-difference/laplacian-part1/README.html)
[27](https://cs.mcgill.ca/~wlh/comp766/files/chapter4_draft_mar29.pdf)
[28](https://github.com/pyg-team/pytorch_geometric)
[29](https://arxiv.org/html/2312.00836v2)
[30](https://lightning.ai/neuralforge/studios/full-end-to-end-ml-pipeline-in-the-lightning-platform)
[31](https://arxiv.org/html/2505.23438v1)
[32](https://openaccess.thecvf.com/content/WACV2024/papers/Nguyen_SequenceMatch_Revisiting_the_Design_of_Weak-Strong_Augmentations_for_Semi-Supervised_Learning_WACV_2024_paper.pdf)
[33](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02375.pdf)
[34](https://arxiv.org/html/2507.21800v1)
[35](https://stackoverflow.com/questions/63285197/measuring-uncertainty-using-mc-dropout-on-pytorch)
[36](https://github.com/SE-ML/awesome-seml)
[37](https://bea.stollnitz.com/blog/vscode-ml-project/)
[38](https://academic.oup.com/mnras/article/528/2/1711/7517098)
[39](https://www.nature.com/articles/s41540-025-00567-1)
[40](https://www.research.unipd.it/retrieve/91826038-5b3b-4938-b6df-e24f316a7184/Lonappan_2024_J._Cosmol._Astropart._Phys._2024_009.pdf)
[41](https://www.biorxiv.org/content/biorxiv/early/2025/06/11/2024.12.28.630070.full.pdf)
[42](https://www.ifaamas.org/Proceedings/aamas2024/pdfs/p1418.pdf)
[43](https://academic.oup.com/mnras/article/512/1/661/6523375)
[44](https://papers.neurips.cc/paper_files/paper/2022/file/17b598fda495256bef6785c2b76c3217-Paper-Datasets_and_Benchmarks.pdf)
[45](https://ui.adsabs.harvard.edu/abs/2023ursi.confE.196S/abstract)
[46](https://www.research-collection.ethz.ch/server/api/core/bitstreams/7e97c50e-d3b7-41ab-9025-777e6648c8b2/content)
[47](https://www.sciencedirect.com/science/article/abs/pii/S0010465524003850)
[48](https://ui.adsabs.harvard.edu/abs/2025ApJ...981...52C)
[49](https://github.com/adityapatel1010/Physics-Informed-Graph-Neural-Network)
[50](https://www.sciencedirect.com/science/article/abs/pii/S221313371830132X)
[51](https://dl.acm.org/doi/10.1145/3681756.3697879)
[52](https://arxiv.org/html/2506.04201v1)
[53](https://ui.adsabs.harvard.edu/abs/2023ApJ...953..178P/abstract)
[54](https://arxiv.org/html/2501.07938v1)
[55](https://www.gotriple.eu/documents/ftarxivpreprints:oai:arXiv.org:2211.07807)
[56](https://arxiv.org/html/2505.01755v1)
[57](https://ml4sci.org/gsoc/2024/proposal_DEEPLENSE6.html)
[58](https://pmc.ncbi.nlm.nih.gov/articles/PMC9250483/)
[59](https://www.nature.com/articles/s41377-024-01544-9)
[60](https://www.sciencedirect.com/science/article/am/pii/S221313371830132X)
[61](https://innovate.ee.ucla.edu/wp-content/uploads/2019/11/JPROC2949575.pdf)
[62](https://indico.skatelescope.org/event/936/contributions/9146/attachments/8206/13597/Final%20Delensing%20with%20PINN.pdf)
[63](https://www.sciencedirect.com/science/article/pii/S0370269325004514?via%3Dihub)
[64](https://github.com/ghatotkachhh/PINN-Classification)
[65](https://summerofcode.withgoogle.com/archive/2023/projects/eNzfLWS9)
[66](https://github.com/ProjectProRepo/Machine-Learning)
[67](https://github.com/topics/paper-implementations)
[68](https://cygnis.co/blog/integration-of-machine-learning/)
[69](https://github.com/santiagxf/mlproject-sample)
[70](https://www.youtube.com/watch?v=Rv6UFGNmNZg)
[71](https://www.sciencedirect.com/science/article/abs/pii/S0925231224010658)
[72](https://www.kaggle.com/general/4815)
[73](https://www.youtube.com/watch?v=FTBi4NkYalc)
[74](https://arxiv.org/abs/2010.07314)
[75](https://arxiv.org/html/2510.09748)
[76](https://distill.pub/2021/gnn-intro)
[77](https://www.geeksforgeeks.org/deep-learning/graph-neural-networks-with-pytorch/)
[78](https://arxiv.org/html/2411.00835v1)
[79](https://lightning.ai/docs/pytorch/LTS/notebooks/course_UvA-DL/06-graph-neural-networks.html)
[80](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html)
[81](https://pytorch-geometric.readthedocs.io)
[82](https://proceedings.mlr.press/v206/stirn23a/stirn23a.pdf)
[83](https://peekaboo-vision.blogspot.com/2012/05/superpixels-for-python-pretty-slic.html)
[84](https://www.machinelearningmastery.com/a-gentle-introduction-to-the-laplacian/)
[85](https://www.reddit.com/r/MachineLearning/comments/qgqq07/d_is_pytorch_lightning_production_ready/)
[86](https://www.geeksforgeeks.org/machine-learning/pseudo-labelling-semi-supervised-learning/)
[87](https://www.nature.com/articles/s41598-023-40977-x)
[88](https://www.youtube.com/watch?v=SCFQMbKfdLI)
[89](https://arxiv.org/html/2406.13733v1)
[90](https://jonnylaw.rocks/posts/2021-08-16-mc-dropout-uncertainty/)
[91](https://www.sciencedirect.com/science/article/pii/S1474034621001257)
[92](https://www.research.ed.ac.uk/files/469575740/KageEtalArXiv2024AReviewOfPseudo-labeling.pdf)
[93](https://arxiv.org/html/2311.15816v2)